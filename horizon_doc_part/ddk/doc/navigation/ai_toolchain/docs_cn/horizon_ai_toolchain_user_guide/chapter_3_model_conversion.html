

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>3. 模型转换 &mdash; horizon_ai_toolchain_user_guide v1.6.6 文档</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/custom-style.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/translations.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" />
    <link rel="next" title="4. 应用开发" href="chapter_4_application_development.html" />
    <link rel="prev" title="2. 环境部署" href="chapter_2_prerequisites.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> horizon_ai_toolchain_user_guide
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">AI工具链:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="chapter_1_introduction.html">1. 产品介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter_2_prerequisites.html">2. 环境部署</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">3. 模型转换</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id2">3.1. 简介</a></li>
<li class="toctree-l2"><a class="reference internal" href="#fp-model-preparation">3.2. 浮点模型准备</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-check">3.3. 验证模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hb-mapper-checker">3.3.1. 使用 <code class="docutils literal notranslate"><span class="pre">hb_mapper</span> <span class="pre">checker</span></code> 工具检查模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">3.3.2. 检查异常处理</a></li>
<li class="toctree-l3"><a class="reference internal" href="#check-result">3.3.3. 检查结果解读</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">3.3.4. 检查结果的调优指导</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#model-conversion">3.4. 转换模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hb-mapper-makertbin">3.4.1. 使用 <code class="docutils literal notranslate"><span class="pre">hb_mapper</span> <span class="pre">makertbin</span></code> 工具转换模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="#conversion-interpretation">3.4.2. 转换内部过程解读</a></li>
<li class="toctree-l3"><a class="reference internal" href="#prepare-calibration-data">3.4.3. 准备校准数据</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id11">3.4.4. 转换结果解读</a></li>
<li class="toctree-l3"><a class="reference internal" href="#conversion-output">3.4.5. 转换产出物解读</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#performance-evaluation">3.5. 模型性能分析与调优</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hb-perf">3.5.1. 使用 <code class="docutils literal notranslate"><span class="pre">hb_perf</span></code> 工具估计性能</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id15">3.5.2. 开发板实测性能</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-performance-optimization">3.5.3. 模型性能优化</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#yaml">3.5.3.1. 检查影响模型性能的yaml参数</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cpu">3.5.3.2. 处理CPU算子</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id17">3.5.3.3. 高性能模型设计建议</a></li>
<li class="toctree-l4"><a class="reference internal" href="#bpu">3.5.3.4. BPU面向高效率模型优化</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#accuracy-evaluation">3.6. 模型精度分析与调优</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id19">3.6.1. 模型精度分析</a></li>
<li class="toctree-l3"><a class="reference internal" href="#accuracy-optimization">3.6.2. 精度调优</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id21">3.6.2.1. 精度有明显损失（4%以上）</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id22">3.6.2.2. 较小精度损失提升</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#op-restrictions">3.7. 算子约束</a></li>
<li class="toctree-l2"><a class="reference internal" href="#other-tools">3.8. 其他模型工具（可选）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id25">3.8.1. 模型打包</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id26">3.8.2. 模型信息查看</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bin">3.8.3. bin模型节点修改</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id27">3.9. 常见问题</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#bpucpu">3.9.1. 如何理解算子约束中提及的BPU支持和CPU支持等算子支持形式</a></li>
<li class="toctree-l3"><a class="reference internal" href="#benchmark">3.9.2. 实测性能与benchmark材料不一致</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bit">3.9.3. 模型量化方式采用的是对称量化还是非对称量化？是否支持16bit量化？</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id28">3.9.4. 如何正确看待模型分段对性能的影响</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id29">3.9.5. 哪些模型转换配置参数会影响最终模型性能？</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id30">3.9.6. 是否支持模型稀疏性优化？</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id31">3.9.7. 理解模型尾部部分BPU可支持算子运行在CPU上</a></li>
<li class="toctree-l3"><a class="reference internal" href="#batch">3.9.8. 是否支持Batch模式</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="chapter_4_application_development.html">4. 应用开发</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter_5_custom_op_development.html">5. 自定义算子开发</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter_6_FAQs.html">6. 常见问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter_7_appendix.html">7. 附录</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">horizon_ai_toolchain_user_guide</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li><span class="section-number">3. </span>模型转换</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/chapter_3_model_conversion.rst.txt" rel="nofollow"> 查看页面源码</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="id1">
<h1><span class="section-number">3. </span>模型转换<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h1>
<div class="section" id="id2">
<h2><span class="section-number">3.1. </span>简介<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<p>模型转换是指将原始浮点模型转换为地平线混合异构模型的过程。
原始浮点模型（文中部分地方也称为浮点模型）是指您通过TensorFlow/PyTorch等等DL框架训练得到的
可用模型，这个模型的计算精度为float32；混合异构模型一种适合在地平线芯片上运行的模型格式。
本章节将反复使用到这两种模型名词，为避免理解歧义，请先理解这个概念再阅读下文。</p>
<p>配合地平线工具链的模型完整开发过程，需要经过 <strong>浮点模型准备</strong>、<strong>模型验证</strong>、<strong>模型转换</strong>、
<strong>性能评估</strong> 和 <strong>精度评估</strong> 共五个重要阶段，如下图。</p>
<a class="reference internal image-reference" href="_images/model_conversion_flowchart.png"><img alt="_images/model_conversion_flowchart.png" class="align-center" src="_images/model_conversion_flowchart.png" style="width: 698.4000000000001px; height: 267.2px;" /></a>
<p><strong>浮点模型准备</strong> 阶段的产出是输入到模型转换工具的浮点模型，
这些模型一般都是基于公开DL训练框架得到的，
需要您注意的是将模型导出为地平线工具支持的格式。
具体要求与建议请参考 <a class="reference internal" href="#fp-model-preparation"><span class="std std-ref">浮点模型准备</span></a>。</p>
<p><strong>模型验证</strong> 阶段用来确保算法模型是符合工具链要求的。
地平线提供了指定工具完成此阶段检查，对于不符合要求的情况，
检查工具会明确给出不符合要求的具体算子信息，方便您结合算子约束的说明将模型调整过来。
具体使用请参考 <a class="reference internal" href="#model-check"><span class="std std-ref">检查模型</span></a>。</p>
<p><strong>模型转换</strong> 阶段将完成浮点模型到地平线混合异构模型的转换。
为了模型能在地平线芯片上高效运行，地平线转换工具内部会完成模型优化、量化和编译等关键步骤，
地平线的量化方法经过了长期的技术与生产验证，在大部分典型模型上可以达到99%以上的精度保持效果。
具体使用请参考 <a class="reference internal" href="#model-conversion"><span class="std std-ref">转换模型</span></a>。</p>
<p><strong>性能评估</strong> 阶段提供了系列评估模型性能的工具。
在应用部署前，您可以使用这些工具验证模型性能是否达到应用要求。
对于部分性能不及预期的情况，也可以参考地平线提供的性能优化建议进行调优。
具体评估请参考 <a class="reference internal" href="#performance-evaluation"><span class="std std-ref">模型性能分析与调优</span></a>。</p>
<p><strong>精度评估</strong> 阶段提供了系列评估模型精度的工具。
大部分情况下，地平线转换后模型可以保持与原始浮点模型基本一致的精度效果，
在应用部署前，您可以使用地平线工具验证模型的精度是否符合预期。
对于部分精度不及预期的情况，也可以参考地平线提供的性能优化建议进行调优。
具体评估请参考 <a class="reference internal" href="#accuracy-evaluation"><span class="std std-ref">模型精度分析与调优</span></a>。</p>
<div class="admonition attention">
<p class="admonition-title">注意</p>
<p>通常在模型转换后就已经得到了可以上板的模型，
但是为了确保您得到的模型性能和精度都是符合应用要求的，
地平线强烈建议每次转换后都完成后续的性能评估与精度评估步骤。</p>
</div>
</div>
<div class="section" id="fp-model-preparation">
<span id="id3"></span><h2><span class="section-number">3.2. </span>浮点模型准备<a class="headerlink" href="#fp-model-preparation" title="永久链接至标题">¶</a></h2>
<p>基于公开DL框架训练得到的浮点模型是转换工具的输入，目前转换工具支持的DL框架如下：</p>
<table class="docutils align-center">
<colgroup>
<col style="width: 27%" />
<col style="width: 10%" />
<col style="width: 13%" />
<col style="width: 18%" />
<col style="width: 10%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><strong>框架</strong></p></th>
<th class="head"><p>Caffe</p></th>
<th class="head"><p>PyTorch</p></th>
<th class="head"><p>TensorFlow</p></th>
<th class="head"><p>MXNet</p></th>
<th class="head"><p>其他框架</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>地平线工具链</strong></p></td>
<td><p>支持</p></td>
<td colspan="3"><p>支持（转ONNX）</p></td>
<td><p>请联系地平线</p></td>
</tr>
</tbody>
</table>
<p>以上框架中，Caffe导出的caffemodel是直接支持的；
PyTorch、TensorFlow和MXNet是通过转到ONNX实现间接支持，
ONNX目前主要支持的opset版本是opset10和opset11。</p>
<p>对于不同框架到ONNX的转换，目前都有对应的标准化方案，参考如下：</p>
<dl class="simple">
<dt>🔗 Pytorch2Onnx：PytTorch官方API支持直接将模型导出为ONNX模型，参考链接：</dt><dd><p><a class="reference external" href="https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html">https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html</a>。</p>
</dd>
<dt>🔗 Tensorflow2Onnx：基于ONNX社区的onnx/tensorflow-onnx 进行转换，参考链接：</dt><dd><p><a class="reference external" href="https://github.com/onnx/tensorflow-onnx">https://github.com/onnx/tensorflow-onnx</a>。</p>
</dd>
<dt>🔗 MXNet2Onnx：MXNet官方API支持直接将模型导出为ONNX模型，参考链接：</dt><dd><p><a class="reference external" href="https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/OnnxConversionTest.cs">https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/OnnxConversionTest.cs</a>。</p>
</dd>
<dt>🔗 更多框架的ONNX转换支持，参考链接：</dt><dd><p><a class="reference external" href="https://github.com/onnx/tutorials#converting-to-onnx-format">https://github.com/onnx/tutorials#converting-to-onnx-format</a>。</p>
</dd>
</dl>
</div>
<div class="section" id="model-check">
<span id="id4"></span><h2><span class="section-number">3.3. </span>验证模型<a class="headerlink" href="#model-check" title="永久链接至标题">¶</a></h2>
<p>为了确保模型能顺利在地平线平台高效运行，模型中所使用的算子需要符合平台的算子约束。
算子约束部分给出了我们支持的具体算子，每个算子都给出了具体的参数限制，
具体详细信息请参考
<cite>supported_op_list_and_restrictions/</cite>
路径下的《supported_op_list_and_restrictions_release_${version}》Excel表格。
考虑到地平线支持的算子较多，为了避免人工逐条校对的麻烦，
我们提供了 <code class="docutils literal notranslate"><span class="pre">hb_mapper</span> <span class="pre">checker</span></code> 工具用于检查模型所使用算子的支持情况。</p>
<div class="section" id="hb-mapper-checker">
<h3><span class="section-number">3.3.1. </span>使用 <code class="docutils literal notranslate"><span class="pre">hb_mapper</span> <span class="pre">checker</span></code> 工具检查模型<a class="headerlink" href="#hb-mapper-checker" title="永久链接至标题">¶</a></h3>
<dl class="py data">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">hb_mapper</span> <span class="pre">checker</span> <span class="pre">工具的使用方式如下：</span></span></dt>
<dd><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hb_mapper checker --model-type <span class="si">${</span><span class="nv">model_type</span><span class="si">}</span> <span class="se">\</span>
                  --march <span class="si">${</span><span class="nv">march</span><span class="si">}</span> <span class="se">\</span>
                  --proto <span class="si">${</span><span class="nv">proto</span><span class="si">}</span> <span class="se">\</span>
                  --model <span class="si">${</span><span class="nv">caffe_model</span><span class="p">/onnx_model</span><span class="si">}</span> <span class="se">\</span>
                  --input-shape <span class="si">${</span><span class="nv">input_node</span><span class="si">}</span> <span class="si">${</span><span class="nv">input_shape</span><span class="si">}</span> <span class="se">\</span>
                  --output <span class="si">${</span><span class="nv">output</span><span class="si">}</span>
</pre></div>
</div>
</dd></dl>

<dl class="py data">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">hb_mapper</span> <span class="pre">checker</span> <span class="pre">参数解释：</span></span></dt>
<dd><dl class="option-list">
<dt><kbd><span class="option">--model-type</span></kbd></dt>
<dd><p>用于指定检查输入的模型类型，目前只支持设置 <code class="docutils literal notranslate"><span class="pre">caffe</span></code> 或者 <code class="docutils literal notranslate"><span class="pre">onnx</span></code>。</p>
</dd>
<dt><kbd><span class="option">--march</span></kbd></dt>
<dd><p>用于指定需要适配的AI芯片类型，可设置值为 <code class="docutils literal notranslate"><span class="pre">bernoulli2</span></code> 和 <code class="docutils literal notranslate"><span class="pre">bayes1</span></code>，
分别对应X3&amp;J3和J5芯片，根据您需要适配的平台选择即可。</p>
</dd>
<dt><kbd><span class="option">--proto</span></kbd></dt>
<dd><p>此参数仅在 <code class="docutils literal notranslate"><span class="pre">model-type</span></code> 指定 <code class="docutils literal notranslate"><span class="pre">caffe</span></code> 时有效，取值为Caffe模型的prototxt文件名称。</p>
</dd>
<dt><kbd><span class="option">--model</span></kbd></dt>
<dd><p>在 <code class="docutils literal notranslate"><span class="pre">model-type</span></code> 被指定为 <code class="docutils literal notranslate"><span class="pre">caffe</span></code> 时，取值为Caffe模型的caffemodel文件名称。
在 <code class="docutils literal notranslate"><span class="pre">model-type</span></code>  被指定为 <code class="docutils literal notranslate"><span class="pre">onnx</span></code> 时，取值为ONNX模型文件名称。</p>
</dd>
<dt><kbd><span class="option">--input-shape</span></kbd></dt>
<dd><p>可选参数，明确指定模型的输入shape。
取值为 <code class="docutils literal notranslate"><span class="pre">{input_name}</span> <span class="pre">{NxHxWxC/NxCxHxW}</span></code> ，<code class="docutils literal notranslate"><span class="pre">input_name</span></code> 与shape之间以空格分隔。
例如模型输入名称为 <code class="docutils literal notranslate"><span class="pre">data1</span></code>，输入shape为 <code class="docutils literal notranslate"><span class="pre">[1,224,224,3]</span></code>，
则配置应该为 <code class="docutils literal notranslate"><span class="pre">--input_shape</span> <span class="pre">data1</span> <span class="pre">1x224x224x3</span></code>。
如果此处配置shape与模型内shape信息不一致，以此处配置为准。</p>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>注意一个 <code class="docutils literal notranslate"><span class="pre">--input-shape</span></code> 只接受一个name和shape组合，如果您的模型有多个输入节点，
在命令中多次配置 <code class="docutils literal notranslate"><span class="pre">--input-shape</span></code> 参数即可。</p>
</div>
</dd>
<dt><kbd><span class="option">--output</span></kbd></dt>
<dd><p>可选参数，接受设置值为一个日志文件名称。
指定该参数情况下，检查的结果将输出到指定的日志文件。</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="id5">
<h3><span class="section-number">3.3.2. </span>检查异常处理<a class="headerlink" href="#id5" title="永久链接至标题">¶</a></h3>
<p>如果模型检查不通过，<code class="docutils literal notranslate"><span class="pre">hb_mapper</span> <span class="pre">checker</span></code> 工具会报出ERROR。
在当前工作目录下会生成checker_result.txt文件，从文件中可以查看到具体的报错。
例如以下配置中含不可识别算子类型 <code class="docutils literal notranslate"><span class="pre">Accuracy</span></code>：</p>
<div class="highlight-ProtoBuf notranslate"><div class="highlight"><pre><span></span><span class="n">layer</span> <span class="p">{</span>
  <span class="n">name</span><span class="o">:</span> <span class="s">&quot;data&quot;</span>
  <span class="n">type</span><span class="o">:</span> <span class="s">&quot;Input&quot;</span>
  <span class="n">top</span><span class="o">:</span> <span class="s">&quot;data&quot;</span>
  <span class="n">input_param</span> <span class="p">{</span> <span class="n">shape</span><span class="o">:</span> <span class="p">{</span> <span class="n">dim</span><span class="o">:</span> <span class="mi">1</span> <span class="n">dim</span><span class="o">:</span> <span class="mi">3</span> <span class="n">dim</span><span class="o">:</span> <span class="mi">224</span> <span class="n">dim</span><span class="o">:</span> <span class="mi">224</span> <span class="p">}</span> <span class="p">}</span>
<span class="p">}</span>
<span class="n">layer</span> <span class="p">{</span>
  <span class="n">name</span><span class="o">:</span> <span class="s">&quot;Convolution1&quot;</span>
  <span class="n">type</span><span class="o">:</span> <span class="s">&quot;Convolution&quot;</span>
  <span class="n">bottom</span><span class="o">:</span> <span class="s">&quot;data&quot;</span>
  <span class="n">top</span><span class="o">:</span> <span class="s">&quot;Convolution1&quot;</span>
  <span class="n">convolution_param</span> <span class="p">{</span>
    <span class="n">num_output</span><span class="o">:</span> <span class="mi">128</span>
    <span class="n">bias_term</span><span class="o">:</span> <span class="kc">false</span>
    <span class="n">pad</span><span class="o">:</span> <span class="mi">0</span>
    <span class="n">kernel_size</span><span class="o">:</span> <span class="mi">1</span>
    <span class="n">group</span><span class="o">:</span> <span class="mi">1</span>
    <span class="n">stride</span><span class="o">:</span> <span class="mi">1</span>
    <span class="n">weight_filler</span> <span class="p">{</span>
      <span class="n">type</span><span class="o">:</span> <span class="s">&quot;msra&quot;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
<span class="n">layer</span> <span class="p">{</span>
  <span class="n">name</span><span class="o">:</span> <span class="s">&quot;accuracy&quot;</span>
  <span class="n">type</span><span class="o">:</span> <span class="s">&quot;Accuracy&quot;</span>
  <span class="n">bottom</span><span class="o">:</span> <span class="s">&quot;Convolution3&quot;</span>
  <span class="n">top</span><span class="o">:</span> <span class="s">&quot;accuracy&quot;</span>
  <span class="n">include</span> <span class="p">{</span>
    <span class="n">phase</span><span class="o">:</span> <span class="n">TEST</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>使用 <code class="docutils literal notranslate"><span class="pre">hb_mapper</span> <span class="pre">checker</span></code> 检查这个模型，您会在checker_result.txt中得到如下信息：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ValueError: Not support layer <span class="nv">name</span><span class="o">=</span>accuracy <span class="nv">type</span><span class="o">=</span>Accuracy
</pre></div>
</div>
</div>
<div class="section" id="check-result">
<span id="id6"></span><h3><span class="section-number">3.3.3. </span>检查结果解读<a class="headerlink" href="#check-result" title="永久链接至标题">¶</a></h3>
<p>如果不存在ERROR，则顺利通过校验。<code class="docutils literal notranslate"><span class="pre">hb_mapper</span> <span class="pre">checker</span></code> 工具将直接输出如下信息：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">==============================================</span>
<span class="n">Node</span>         <span class="n">ON</span>   <span class="n">Subgraph</span>  <span class="n">Type</span>
<span class="o">----------------------------------------------</span>
<span class="n">conv1</span>        <span class="n">BPU</span>  <span class="nb">id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>     <span class="n">HzSQuantizedConv</span>
<span class="n">conv2_1</span><span class="o">/</span><span class="n">dw</span>   <span class="n">BPU</span>  <span class="nb">id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>     <span class="n">HzSQuantizedConv</span>
<span class="n">conv2_1</span><span class="o">/</span><span class="n">sep</span>  <span class="n">BPU</span>  <span class="nb">id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>     <span class="n">HzSQuantizedConv</span>
<span class="n">conv2_2</span><span class="o">/</span><span class="n">dw</span>   <span class="n">BPU</span>  <span class="nb">id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>     <span class="n">HzSQuantizedConv</span>
<span class="n">conv2_2</span><span class="o">/</span><span class="n">sep</span>  <span class="n">BPU</span>  <span class="nb">id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>     <span class="n">HzSQuantizedConv</span>
<span class="n">conv3_1</span><span class="o">/</span><span class="n">dw</span>   <span class="n">BPU</span>  <span class="nb">id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>     <span class="n">HzSQuantizedConv</span>
<span class="n">conv3_1</span><span class="o">/</span><span class="n">sep</span>  <span class="n">BPU</span>  <span class="nb">id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>     <span class="n">HzSQuantizedConv</span>
<span class="o">...</span>
</pre></div>
</div>
<p>结果中每行都代表一个模型节点的check情况，每行含Node、ON、Subgraph和Type四列，
分别为节点名称、执行节点计算的硬件、节点所属子图和节点映射到的地平线内部实现名称。
如果模型在非输入和输出部分出现了CPU计算的算子，工具将把这个算子前后连续在BPU计算的部分拆分为两个Subgraph（子图）。</p>
</div>
<div class="section" id="id7">
<h3><span class="section-number">3.3.4. </span>检查结果的调优指导<a class="headerlink" href="#id7" title="永久链接至标题">¶</a></h3>
<p>在最理想的情况下，非输入和输出部分都应该在BPU上运行，也就是只有一个子图。
如果出现了CPU算子导致拆分多个子图，<code class="docutils literal notranslate"><span class="pre">hb_mapper</span> <span class="pre">checker</span></code> 工具会给出导致CPU算子出现的具体原因。
例如以下Caffe模型的Convolution2使用了9x9 kernel，超出了Convolution的算子约束。</p>
<div class="highlight-ProtoBuf notranslate"><div class="highlight"><pre><span></span><span class="n">layer</span> <span class="p">{</span>
  <span class="n">name</span><span class="o">:</span> <span class="s">&quot;data&quot;</span>
  <span class="n">type</span><span class="o">:</span> <span class="s">&quot;Input&quot;</span>
  <span class="n">top</span><span class="o">:</span> <span class="s">&quot;data&quot;</span>
  <span class="n">input_param</span> <span class="p">{</span> <span class="n">shape</span><span class="o">:</span> <span class="p">{</span> <span class="n">dim</span><span class="o">:</span> <span class="mi">1</span> <span class="n">dim</span><span class="o">:</span> <span class="mi">3</span> <span class="n">dim</span><span class="o">:</span> <span class="mi">224</span> <span class="n">dim</span><span class="o">:</span> <span class="mi">224</span> <span class="p">}</span> <span class="p">}</span>
<span class="p">}</span>
<span class="n">layer</span> <span class="p">{</span>
  <span class="n">name</span><span class="o">:</span> <span class="s">&quot;Convolution1&quot;</span>
  <span class="n">type</span><span class="o">:</span> <span class="s">&quot;Convolution&quot;</span>
  <span class="n">bottom</span><span class="o">:</span> <span class="s">&quot;data&quot;</span>
  <span class="n">top</span><span class="o">:</span> <span class="s">&quot;Convolution1&quot;</span>
  <span class="n">convolution_param</span> <span class="p">{</span>
    <span class="n">num_output</span><span class="o">:</span> <span class="mi">128</span>
    <span class="n">bias_term</span><span class="o">:</span> <span class="kc">false</span>
    <span class="n">pad</span><span class="o">:</span> <span class="mi">0</span>
    <span class="n">kernel_size</span><span class="o">:</span> <span class="mi">1</span>
    <span class="n">group</span><span class="o">:</span> <span class="mi">1</span>
    <span class="n">stride</span><span class="o">:</span> <span class="mi">1</span>
    <span class="n">weight_filler</span> <span class="p">{</span>
      <span class="n">type</span><span class="o">:</span> <span class="s">&quot;msra&quot;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
<span class="n">layer</span> <span class="p">{</span>
  <span class="n">name</span><span class="o">:</span> <span class="s">&quot;Convolution2&quot;</span>
  <span class="n">type</span><span class="o">:</span> <span class="s">&quot;Convolution&quot;</span>
  <span class="n">bottom</span><span class="o">:</span> <span class="s">&quot;Convolution1&quot;</span>
  <span class="n">top</span><span class="o">:</span> <span class="s">&quot;Convolution2&quot;</span>
  <span class="n">convolution_param</span> <span class="p">{</span>
    <span class="n">num_output</span><span class="o">:</span> <span class="mi">128</span>
    <span class="n">bias_term</span><span class="o">:</span> <span class="kc">false</span>
    <span class="n">pad</span><span class="o">:</span> <span class="mi">4</span>
    <span class="n">kernel_size</span><span class="o">:</span> <span class="mi">9</span>
    <span class="n">group</span><span class="o">:</span> <span class="mi">1</span>
    <span class="n">stride</span><span class="o">:</span> <span class="mi">1</span>
    <span class="n">weight_filler</span> <span class="p">{</span>
      <span class="n">type</span><span class="o">:</span> <span class="s">&quot;msra&quot;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
<span class="n">layer</span> <span class="p">{</span>
  <span class="n">name</span><span class="o">:</span> <span class="s">&quot;Convolution3&quot;</span>
  <span class="n">type</span><span class="o">:</span> <span class="s">&quot;Convolution&quot;</span>
  <span class="n">bottom</span><span class="o">:</span> <span class="s">&quot;Convolution2&quot;</span>
  <span class="n">top</span><span class="o">:</span> <span class="s">&quot;Convolution3&quot;</span>
  <span class="n">convolution_param</span> <span class="p">{</span>
    <span class="n">num_output</span><span class="o">:</span> <span class="mi">128</span>
    <span class="n">bias_term</span><span class="o">:</span> <span class="kc">false</span>
    <span class="n">pad</span><span class="o">:</span> <span class="mi">1</span>
    <span class="n">kernel_size</span><span class="o">:</span> <span class="mi">3</span>
    <span class="n">group</span><span class="o">:</span> <span class="mi">1</span>
    <span class="n">stride</span><span class="o">:</span> <span class="mi">1</span>
    <span class="n">weight_filler</span> <span class="p">{</span>
      <span class="n">type</span><span class="o">:</span> <span class="s">&quot;msra&quot;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>使用 <code class="docutils literal notranslate"><span class="pre">hb_mapper</span> <span class="pre">checker</span></code> 工具检查这个模型时，您将得到kernel超出约束的提示如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="lineno">1 </span>Layer Convolution2
<span class="lineno">2 </span>        Expected data shape range of Kernel shape is <span class="o">[[</span><span class="m">1</span>, <span class="m">2048</span><span class="o">]</span>,<span class="o">[</span><span class="m">1</span>, <span class="m">7</span><span class="o">]</span>,<span class="o">[</span><span class="m">1</span>, <span class="m">7</span><span class="o">]</span>,<span class="o">[</span><span class="m">1</span>, <span class="m">2048</span><span class="o">]]</span>, but the data shape is <span class="o">[</span><span class="m">128</span>,9,9,128<span class="o">]</span>
</pre></div>
</div>
<p>模型最终检查结果也会出现一个以上的分段，如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">===============================================</span>
Node          ON   Subgraph  Type
-----------------------------------------------
Convolution1  BPU  id<span class="o">(</span><span class="m">0</span><span class="o">)</span>     HzSQuantizedConv
Convolution2  CPU  --        Conv
Convolution3  BPU  id<span class="o">(</span><span class="m">1</span><span class="o">)</span>     HzSQuantizedConv
</pre></div>
</div>
<p>根据 <code class="docutils literal notranslate"><span class="pre">hb_mapper</span> <span class="pre">checker</span></code> 给出的提示，如果需要更高的性能，您需要将Convolution2的kernel调整到限制范围内。
<strong>当然，多个子图也不会影响整个转换流程，如果在后续性能评估不达预期，您再根据这里的建议尽量将算子调整到BPU上运行。</strong></p>
</div>
</div>
<div class="section" id="model-conversion">
<span id="id8"></span><h2><span class="section-number">3.4. </span>转换模型<a class="headerlink" href="#model-conversion" title="永久链接至标题">¶</a></h2>
<p>转换模型阶段会完成浮点模型到地平线混合异构模型的转换，经过这个阶段，您将得到一个可以在地平线芯片上运行的模型。
在进行转换之前，请确保已经顺利通过了3.3节的检查模型过程。</p>
<p>模型转换使用 <code class="docutils literal notranslate"><span class="pre">hb_mapper</span> <span class="pre">makertbin</span></code> 工具完成，转换期间会完成模型优化和校准量化等重要过程，校准需要依照模型预处理要求准备校准数据。
为了方便您全面了解模型转换，本节将依次介绍转换工具使用、校准数据准备、转换内部过程解读、转换结果解读和转换产出物解读。</p>
<div class="section" id="hb-mapper-makertbin">
<span id="makertbin"></span><h3><span class="section-number">3.4.1. </span>使用 <code class="docutils literal notranslate"><span class="pre">hb_mapper</span> <span class="pre">makertbin</span></code> 工具转换模型<a class="headerlink" href="#hb-mapper-makertbin" title="永久链接至标题">¶</a></h3>
<dl class="py data">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">hb_mapper</span> <span class="pre">makertbin命令使用方式如下：</span></span></dt>
<dd><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hb_mapper makertbin --config <span class="si">${</span><span class="nv">config_file</span><span class="si">}</span>  <span class="se">\</span>
                    --model-type  <span class="si">${</span><span class="nv">model_type</span><span class="si">}</span>
</pre></div>
</div>
</dd></dl>

<dl class="py data">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">hb_mapper</span> <span class="pre">makertbin参数解释：</span></span></dt>
<dd><dl class="option-list">
<dt><kbd><span class="option">--model-type</span></kbd></dt>
<dd><p>用于指定转换输入的模型类型，目前支持设置Caffe或者ONNX。</p>
</dd>
<dt><kbd><span class="option">--config</span></kbd></dt>
<dd><p>模型编译的配置文件，内容采用yaml格式，文件名使用.yaml后缀。一份完整的配置文件模板如下：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># 模型参数组</span>
<span class="n">model_parameters</span><span class="p">:</span>
  <span class="c1"># 原始Caffe浮点模型描述文件</span>
  <span class="n">prototxt</span><span class="p">:</span> <span class="s1">&#39;***.prototxt&#39;</span>

  <span class="c1"># 原始Caffe浮点模型数据模型文件</span>
  <span class="n">caffe_model</span><span class="p">:</span> <span class="s1">&#39;****.caffemodel&#39;</span>

  <span class="c1"># 原始Onnx浮点模型文件</span>
  <span class="n">onnx_model</span><span class="p">:</span> <span class="s1">&#39;****.onnx&#39;</span>

  <span class="c1"># 转换的目标AI芯片架构</span>
  <span class="n">march</span><span class="p">:</span> <span class="s1">&#39;bernoulli2&#39;</span>

  <span class="c1"># 模型转换输出的用于上板执行的模型文件的名称前缀</span>
  <span class="n">output_model_file_prefix</span><span class="p">:</span> <span class="s1">&#39;mobilenetv1&#39;</span>

  <span class="c1"># 模型转换输出的结果的存放目录</span>
  <span class="n">working_dir</span><span class="p">:</span> <span class="s1">&#39;./model_output_dir&#39;</span>

  <span class="c1"># 指定转换后混合异构模型是否保留输出各层的中间结果的能力</span>
  <span class="n">layer_out_dump</span><span class="p">:</span> <span class="kc">False</span>

  <span class="c1"># 转换过程中日志生成级别</span>
  <span class="n">log_level</span><span class="p">:</span> <span class="s1">&#39;debug&#39;</span>

<span class="c1"># 输入信息参数组</span>
<span class="n">input_parameters</span><span class="p">:</span>
  <span class="c1"># 原始浮点模型的输入节点名称</span>
  <span class="n">input_name</span><span class="p">:</span> <span class="n">data</span>

  <span class="c1"># 原始浮点模型的输入数据格式（数量/顺序与input_name一致）</span>
  <span class="n">input_type_train</span><span class="p">:</span> <span class="s1">&#39;bgr&#39;</span>

  <span class="c1"># 原始浮点模型的输入数据排布（数量/顺序与input_name一致）</span>
  <span class="n">input_layout_train</span><span class="p">:</span> <span class="s1">&#39;NCHW&#39;</span>

  <span class="c1"># 原始浮点模型的输入数据尺寸</span>
  <span class="n">input_shape</span><span class="p">:</span> <span class="s1">&#39;1x3x224x224&#39;</span>

  <span class="c1"># 在模型中添加的输入数据预处理方法</span>
  <span class="n">norm_type</span><span class="p">:</span> <span class="s1">&#39;data_mean_and_scale&#39;</span>

  <span class="c1"># 预处理方法的图像减去的均值, 如果是通道均值，value之间必须用空格分隔</span>
  <span class="n">mean_value</span><span class="p">:</span> <span class="s1">&#39;103.94 116.78 123.68&#39;</span>

  <span class="c1"># 预处理方法的图像缩放比例，如果是通道缩放比例，value之间必须用空格分隔</span>
  <span class="n">scale_value</span><span class="p">:</span> <span class="s1">&#39;0.017&#39;</span>

  <span class="c1"># 转换后混合异构模型需要适配的输入数据格式（数量/顺序与input_name一致）</span>
  <span class="n">input_type_rt</span><span class="p">:</span> <span class="s1">&#39;yuv444&#39;</span>

  <span class="c1"># 输入数据格式的特殊制式</span>
  <span class="n">input_space_and_range</span><span class="p">:</span> <span class="s1">&#39;regular&#39;</span>

  <span class="c1"># 转换后混合异构模型需要适配的输入数据排布（数量/顺序与input_name一致）</span>
  <span class="n">input_layout_rt</span><span class="p">:</span> <span class="s1">&#39;NHWC&#39;</span>

<span class="c1"># 校准参数组</span>
<span class="n">calibration_parameters</span><span class="p">:</span>
  <span class="c1"># 模型校准使用的标定样本的存放目录</span>
  <span class="n">cal_data_dir</span><span class="p">:</span> <span class="s1">&#39;./calibration_data&#39;</span>

  <span class="c1"># 开启图片校准样本自动处理（skimage read; resize到输入节点尺寸）</span>
  <span class="n">preprocess_on</span><span class="p">:</span> <span class="kc">False</span>

  <span class="c1"># 校准使用的算法类型</span>
  <span class="n">calibration_type</span><span class="p">:</span> <span class="s1">&#39;kl&#39;</span>

  <span class="c1"># max 校准方式的参数</span>
  <span class="n">max_percentile</span><span class="p">:</span> <span class="mf">1.0</span>

  <span class="c1"># 强制指定OP在CPU上运行</span>
  <span class="n">run_on_cpu</span><span class="p">:</span>  <span class="p">{</span><span class="n">OP_name</span><span class="p">}</span>

  <span class="c1"># 强制指定OP在BPU上运行</span>
  <span class="n">run_on_bpu</span><span class="p">:</span>  <span class="p">{</span><span class="n">OP_name</span><span class="p">}</span>

<span class="c1"># 编译参数组</span>
<span class="n">compiler_parameters</span><span class="p">:</span>
  <span class="c1"># 编译策略选择</span>
  <span class="n">compile_mode</span><span class="p">:</span> <span class="s1">&#39;latency&#39;</span>

  <span class="c1"># 是否打开编译的debug信息</span>
  <span class="n">debug</span><span class="p">:</span> <span class="kc">False</span>

  <span class="c1"># 模型运行核心数</span>
  <span class="n">core_num</span><span class="p">:</span> <span class="mi">1</span>

  <span class="c1"># 模型编译的优化等级选择</span>
  <span class="n">optimize_level</span><span class="p">:</span> <span class="s1">&#39;O3&#39;</span>

<span class="n">custom_op</span><span class="p">:</span>
  <span class="c1"># 自定义op的校准方式, 推荐使用注册方式 register</span>
  <span class="n">custom_op_method</span><span class="p">:</span> <span class="n">register</span>

  <span class="c1"># 自定义OP的实现文件, 多个文件可用&quot;;&quot;分隔, 该文件可由模板生成, 详情见自定义OP相关文档</span>
  <span class="n">op_register_files</span><span class="p">:</span> <span class="n">sample_custom</span><span class="o">.</span><span class="n">py</span>

  <span class="c1"># 自定义OP实现文件所在的文件夹, 请使用相对路径</span>
  <span class="n">custom_op_dir</span><span class="p">:</span> <span class="o">./</span><span class="n">custom_op</span>
</pre></div>
</div>
<p>配置文件主要包含模型参数组、输入信息参数组、校准参数组和编译参数组。
在您的配置文件中，四个参数组位置都需要存在，具体参数分为可选和必选，可选参数可以不配置。
具体参数的设置形式为：<code class="docutils literal notranslate"><span class="pre">param_name:</span>&#160; <span class="pre">'param_value'</span></code> ，参数存在多个值时使用 <code class="docutils literal notranslate"><span class="pre">';'</span></code> 符号分隔：
<code class="docutils literal notranslate"><span class="pre">param_name:</span>&#160; <span class="pre">'param_value1;</span> <span class="pre">param_value2;</span> <span class="pre">param_value3'</span></code> 。</p>
<div class="admonition tip">
<p class="admonition-title">小技巧</p>
<p>当模型为多输入模型时, 强烈建议用户将可选参数们(<code class="docutils literal notranslate"><span class="pre">input_name</span></code>, <code class="docutils literal notranslate"><span class="pre">input_shape</span></code> 等)显式的写出, 以免造成参数对应顺序上的错误。</p>
</div>
<p>以下是具体参数信息，参数会比较多，我们依照上述的参数组次序介绍。</p>
<p>🛠️ <strong>模型参数组</strong></p>
<table class="docutils align-center">
<colgroup>
<col style="width: 4%" />
<col style="width: 28%" />
<col style="width: 60%" />
<col style="width: 8%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>编</p>
<p>号</p>
</td>
<td><p>参数名称</p></td>
<td><p>参数配置说明</p></td>
<td><blockquote>
<div><p>可选/</p>
</div></blockquote>
<p>必选</p>
</td>
</tr>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">prototxt</span></code></p></td>
<td><p><strong>参数作用</strong>：指定Caffe浮点模型的prototxt文件名称。</p>
<p><strong>取值范围</strong>：无。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：在 <code class="docutils literal notranslate"><span class="pre">hb_mapper</span> <span class="pre">makertbin</span></code> 的</p>
<p><code class="docutils literal notranslate"><span class="pre">model-type</span></code> 为 <code class="docutils literal notranslate"><span class="pre">caffe</span></code> 时必须配置。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">caffe_model</span></code></p></td>
<td><p><strong>参数作用</strong>：指定Caffe浮点模型的caffemodel文件名称。</p>
<p><strong>取值范围</strong>：无。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：在 <code class="docutils literal notranslate"><span class="pre">hb_mapper</span> <span class="pre">makertbin</span></code> 的</p>
<p><code class="docutils literal notranslate"><span class="pre">model-type</span></code> 为 <code class="docutils literal notranslate"><span class="pre">caffe</span></code> 时必须配置。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">onnx_model</span></code></p></td>
<td><p><strong>参数作用</strong>：指定ONNX浮点模型的onnx文件名称。</p>
<p><strong>取值范围</strong>：无。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：在 <code class="docutils literal notranslate"><span class="pre">hb_mapper</span> <span class="pre">makertbin</span></code> 的</p>
<p><code class="docutils literal notranslate"><span class="pre">model-type</span></code> 为 <code class="docutils literal notranslate"><span class="pre">onnx</span></code> 时必须配置。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">march</span></code></p></td>
<td><p><strong>参数作用</strong>：指定产出混合异构模型需要支持的平台架构。</p>
<p><strong>取值范围</strong>：<code class="docutils literal notranslate"><span class="pre">bernoulli2</span></code> 和 <code class="docutils literal notranslate"><span class="pre">bayes1</span></code>。</p>
<p><strong>默认配置</strong>： <code class="docutils literal notranslate"><span class="pre">bernoulli2</span></code>。</p>
<p><strong>参数说明</strong>： 两个可选配置值依次对应X3&amp;J3和J5芯片，</p>
<p>根据您使用的平台选择。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">output_model_file_prefix</span></code></p></td>
<td><p><strong>参数作用</strong>：指定转换产出混合异构模型的名称前缀。</p>
<p><strong>取值范围</strong>：无。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：输出的定点模型文件的名称前缀。</p>
</td>
<td><p>必选</p></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">working_dir</span></code></p></td>
<td><p><strong>参数作用</strong>：指定模型转换输出的结果的存放目录。</p>
<p><strong>取值范围</strong>：无。</p>
<p><strong>默认配置</strong>：<code class="docutils literal notranslate"><span class="pre">model_output</span></code>。</p>
<p><strong>参数说明</strong>：若该目录不存在, 则工具会自动创建目录。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">layer_out_dump</span></code></p></td>
<td><p><strong>参数作用</strong>：指定混合异构模型是否保留输出中间层值的能力。</p>
<p><strong>取值范围</strong>：<code class="docutils literal notranslate"><span class="pre">True</span></code> 、 <code class="docutils literal notranslate"><span class="pre">False</span></code>。</p>
<p><strong>默认配置</strong>：<code class="docutils literal notranslate"><span class="pre">False</span></code>。</p>
<p><strong>参数说明</strong>：输出中间层的值是调试需要用到的手段，</p>
<p>常规状态下请不要开启。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">log_level</span></code></p></td>
<td><p><strong>参数作用</strong>：指定转换工具日志文件的记录级别。</p>
<p><strong>取值范围</strong>：<code class="docutils literal notranslate"><span class="pre">debug</span></code>、 <code class="docutils literal notranslate"><span class="pre">info</span></code>、 <code class="docutils literal notranslate"><span class="pre">warn</span></code>。</p>
<p><strong>默认配置</strong>： <code class="docutils literal notranslate"><span class="pre">debug</span></code>。</p>
<p><strong>参数说明</strong>：<code class="docutils literal notranslate"><span class="pre">debug</span></code> 输出模型转换的详细信息;</p>
<p><code class="docutils literal notranslate"><span class="pre">info</span></code> 只输出关键信息;</p>
<p><code class="docutils literal notranslate"><span class="pre">warn</span></code> 输出警告和错误级别以上的信息。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">output_nodes</span></code></p></td>
<td><p><strong>参数作用</strong>：指定模型的输出节点。</p>
<p><strong>取值范围</strong>：无。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：一般情况下，转换工具会自动识别模型的输出节点。</p>
<p>此参数用于支持您指定一些中间层次作为输出。</p>
<p>设置值为模型中的具体节点名称，</p>
<p>多个值的配置方法请参考前文对 <code class="docutils literal notranslate"><span class="pre">param_value</span></code> 配置描述。</p>
<p>需要您注意的是，一旦设置此参数后，工具将不再自动识别输出节点，</p>
<p>您通过此参数指定的节点就是全部的输出。</p>
</td>
<td><p>可选</p></td>
</tr>
</tbody>
</table>
<p>🛠️ <strong>输入信息参数组</strong></p>
<table class="docutils align-center">
<colgroup>
<col style="width: 3%" />
<col style="width: 23%" />
<col style="width: 68%" />
<col style="width: 7%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>编</p>
<p>号</p>
</td>
<td><p>参数名称</p></td>
<td><p>参数配置说明</p></td>
<td><blockquote>
<div><p>可选/</p>
</div></blockquote>
<p>必选</p>
</td>
</tr>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">input_name</span></code></p></td>
<td><p><strong>参数作用</strong>：指定原始浮点模型的输入节点名称。</p>
<p><strong>取值范围</strong>：无。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：浮点模型只有一个输入节点情况时不需要配置，</p>
<p>多于一个输入节点时必须配置以保证后续类型及校准数据输入顺序的准确性。</p>
<p>多个值的配置方法请参考前文对param_value配置描述。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">input_type_train</span></code></p></td>
<td><p><strong>参数作用</strong>：指定原始浮点模型的输入数据类型。</p>
<p><strong>取值范围</strong>： <code class="docutils literal notranslate"><span class="pre">rgb</span></code> 、 <code class="docutils literal notranslate"><span class="pre">bgr</span></code> 、 <code class="docutils literal notranslate"><span class="pre">yuv444</span></code> 、 <code class="docutils literal notranslate"><span class="pre">gray</span></code> 、 <code class="docutils literal notranslate"><span class="pre">featuremap</span></code>。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：每一个输入节点都需要配置一个确定的输入数据类型，</p>
<p>存在多个输入节点时，设置的节点顺序需要与</p>
<p><code class="docutils literal notranslate"><span class="pre">input_name</span></code> 里的顺序严格保持一致。</p>
<p>多个值的配置方法请参考前文对 <code class="docutils literal notranslate"><span class="pre">param_value</span></code> 配置描述。</p>
<p>数据类型的选择请参考下文</p>
<p><a class="reference internal" href="#conversion-interpretation"><span class="std std-ref">转换内部过程解读</span></a></p>
<p>部分的介绍。</p>
</td>
<td><p>必选</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">input_layout_train</span></code></p></td>
<td><p><strong>参数作用</strong>：指定原始浮点模型的输入数据排布。</p>
<p><strong>取值范围</strong>：<code class="docutils literal notranslate"><span class="pre">NHWC</span></code> 、 <code class="docutils literal notranslate"><span class="pre">NCHW</span></code>。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：每一个输入节点都需要配置一个确定的输入数据排布，</p>
<p>这个排布必须与原始浮点模型所采用的数据排布相同。存在多个输入节点时，</p>
<p>设置的节点顺序需要与 <code class="docutils literal notranslate"><span class="pre">input_name</span></code> 里的顺序严格保持一致。</p>
<p>多个值的配置方法请参考前文对 <code class="docutils literal notranslate"><span class="pre">param_value</span></code> 配置描述。</p>
<p>什么是数据排布请参考下文</p>
<p><a class="reference internal" href="#conversion-interpretation"><span class="std std-ref">转换内部过程解读</span></a></p>
<p>部分的介绍。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">input_type_rt</span></code></p></td>
<td><p><strong>参数作用</strong>：转换后混合异构模型需要适配的输入数据格式。</p>
<p><strong>取值范围</strong>：<code class="docutils literal notranslate"><span class="pre">rgb</span></code> 、 <code class="docutils literal notranslate"><span class="pre">bgr</span></code> 、 <code class="docutils literal notranslate"><span class="pre">yuv444</span></code> 、</p>
<p><code class="docutils literal notranslate"><span class="pre">nv12</span></code> 、 <code class="docutils literal notranslate"><span class="pre">gray</span></code> 、 <code class="docutils literal notranslate"><span class="pre">featuremap</span></code>。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：这里是指明您需要使用的数据格式，</p>
<p>不要求与原始模型的数据格式一致，</p>
<p>但是需要注意在边缘平台喂给模型的数据是使用这个格式。</p>
<p>每一个输入节点都需要配置一个确定的输入数据类型，存在多个输入节点时，</p>
<p>设置的节点顺序需要与 <code class="docutils literal notranslate"><span class="pre">input_name</span></code> 里的顺序严格保持一致。</p>
<p>多个值的配置方法请参考前文对 <code class="docutils literal notranslate"><span class="pre">param_value</span></code> 配置描述。</p>
<p>数据类型的选择请参考下文</p>
<p><a class="reference internal" href="#conversion-interpretation"><span class="std std-ref">转换内部过程解读</span></a></p>
<p>部分的介绍。</p>
</td>
<td><p>必选</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">input_layout_rt</span></code></p></td>
<td><p><strong>参数作用</strong>：转换后混合异构模型需要适配的输入数据排布。</p>
<p><strong>取值范围</strong>： <code class="docutils literal notranslate"><span class="pre">NCHW</span></code> 、 <code class="docutils literal notranslate"><span class="pre">NHWC</span></code>。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：每一个输入节点都需要配置一个确定的输入数据排布，</p>
<p>这个输入是您希望给混合异构模型指定的排布。</p>
<p>不合适的输入数据的排布设置将会影响性能，</p>
<p>X/J3平台建议用户使用 NHWC 格式输入。</p>
<p>存在多个输入节点时，设置的节点顺序需要与</p>
<p><code class="docutils literal notranslate"><span class="pre">input_name</span></code> 里的顺序严格保持一致。</p>
<p>多个值的配置方法请参考前文对 <code class="docutils literal notranslate"><span class="pre">param_value</span></code> 配置描述。</p>
<p>什么是数据排布请参考下文</p>
<p><a class="reference internal" href="#conversion-interpretation"><span class="std std-ref">转换内部过程解读</span></a></p>
<p>部分的介绍。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">input_space_and_range</span></code></p></td>
<td><p><strong>参数作用</strong>：指定输入数据格式的特殊制式。</p>
<p><strong>取值范围</strong>： <code class="docutils literal notranslate"><span class="pre">regular</span></code> , <code class="docutils literal notranslate"><span class="pre">bt601_video</span></code>。</p>
<p><strong>默认配置</strong>： <code class="docutils literal notranslate"><span class="pre">regular</span></code>。</p>
<p><strong>参数说明</strong>：这个参数是为了适配不同ISP输出的yuv420格式，</p>
<p>在相应 <code class="docutils literal notranslate"><span class="pre">input_type_rt</span></code> 为 <code class="docutils literal notranslate"><span class="pre">nv12</span></code> 时，该配置才有效。</p>
<p><code class="docutils literal notranslate"><span class="pre">regular</span></code> 就是常见的yuv420格式，数值范围为 <code class="docutils literal notranslate"><span class="pre">[0,255]</span></code>；</p>
<p><code class="docutils literal notranslate"><span class="pre">bt601_video</span></code> 是另一种视频制式yuv420，数值范围为 <code class="docutils literal notranslate"><span class="pre">[16,235]</span></code>。</p>
<p>更多信息可以通过网络资料了解bt601，</p>
<p>在没有明确需要的情况下，您不要配置此参数。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">input_shape</span></code></p></td>
<td><p><strong>参数作用</strong>：指定原始浮点模型的输入数据尺寸。</p>
<p><strong>取值范围</strong>：无。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：shape的几个维度以 <code class="docutils literal notranslate"><span class="pre">'x'</span></code> 连接，例如 <code class="docutils literal notranslate"><span class="pre">1x3x224x224</span></code>。</p>
<p>原始浮点模型只有一个输入节点情况时可以不配置，</p>
<p>工具会自动读取模型文件中的尺寸信息。</p>
<p>配置多个输入节点时，设置的节点顺序需要与 <code class="docutils literal notranslate"><span class="pre">input_name</span></code></p>
<p>里的顺序严格保持一致，</p>
<p>多个值的配置方法请参考前文对 <code class="docutils literal notranslate"><span class="pre">param_value</span></code> 配置描述。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">norm_type</span></code></p></td>
<td><p><strong>参数作用</strong>：在模型中添加的输入数据预处理方法。</p>
<p><strong>取值范围</strong>： <code class="docutils literal notranslate"><span class="pre">data_mean_and_scale</span></code> 、 <code class="docutils literal notranslate"><span class="pre">data_mean</span></code> 、</p>
<p><code class="docutils literal notranslate"><span class="pre">data_scale</span></code> 、 <code class="docutils literal notranslate"><span class="pre">no_preprocess</span></code>。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>： <code class="docutils literal notranslate"><span class="pre">no_preprocess</span></code> 表示不添加任何数据预处理；</p>
<p><code class="docutils literal notranslate"><span class="pre">data_mean</span></code> 表示提供减均值预处理；</p>
<p><code class="docutils literal notranslate"><span class="pre">data_scale</span></code> 表示提供乘scale系数预处理；</p>
<p><code class="docutils literal notranslate"><span class="pre">data_mean_and_scale</span></code> 表示提供先减均值再乘scale系数前处理。</p>
<p>输入节点时多于一个时，设置的节点顺序需要与 <code class="docutils literal notranslate"><span class="pre">input_name</span></code></p>
<p>里的顺序严格保持一致，</p>
<p>多个值的配置方法请参考前文对 <code class="docutils literal notranslate"><span class="pre">param_value</span></code> 配置描述。</p>
<p>配置该参数的影响请参考下文</p>
<p><a class="reference internal" href="#conversion-interpretation"><span class="std std-ref">转换内部过程解读</span></a></p>
<p>部分的介绍。</p>
</td>
<td><p>必选</p></td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mean_value</span></code></p></td>
<td><p><strong>参数作用</strong>：指定预处理方法的图像减去的均值。</p>
<p><strong>取值范围</strong>：无。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：当 <code class="docutils literal notranslate"><span class="pre">norm_type</span></code> 存在 <code class="docutils literal notranslate"><span class="pre">data_mean_and_scale</span></code></p>
<p>或 <code class="docutils literal notranslate"><span class="pre">data_mean</span></code> 时需要配置该参数。</p>
<p>对于每一个输入节点而言，存在两种配置方式。</p>
<p>第一种是仅配置一个数值，表示所有通道都减去这个均值；</p>
<p>第二种是提供与通道数量一致的数值（这些数值以空格分隔开），</p>
<p>表示每个通道都会减去不同的均值。</p>
<p>配置的输入节点数量必须与 <code class="docutils literal notranslate"><span class="pre">norm_type</span></code> 配置的节点数量一致，</p>
<p>如果存在某个节点不需要 <code class="docutils literal notranslate"><span class="pre">mean</span></code> 处理，则为该节点配置 <code class="docutils literal notranslate"><span class="pre">'None'</span></code>。</p>
<p>多个值的配置方法请参考前文对 <code class="docutils literal notranslate"><span class="pre">param_value</span></code> 配置描述。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">scale_value</span></code></p></td>
<td><p><strong>参数作用</strong>：指定预处理方法的数值scale系数。</p>
<p><strong>取值范围</strong>：无。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：当 <code class="docutils literal notranslate"><span class="pre">norm_type</span></code> 存在 <code class="docutils literal notranslate"><span class="pre">data_mean_and_scale</span></code> 或</p>
<p><code class="docutils literal notranslate"><span class="pre">data_scale</span></code> 时需要配置该参数。</p>
<p>对于每一个输入节点而言，存在两种配置方式。</p>
<p>第一种是仅配置一个数值，表示所有通道都乘以这个系数；</p>
<p>第二种是提供与通道数量一致的数值（这些数值以空格分隔开），</p>
<p>表示每个通道都会乘以不同的系数。</p>
<p>配置的输入节点数量必须与 <code class="docutils literal notranslate"><span class="pre">norm_type</span></code> 配置的节点数量一致，</p>
<p>如果存在某个节点不需要 <code class="docutils literal notranslate"><span class="pre">scale</span></code> 处理，则为该节点配置 <code class="docutils literal notranslate"><span class="pre">'None'</span></code>。</p>
<p>多个值的配置方法请参考前文对 <code class="docutils literal notranslate"><span class="pre">param_value</span></code> 配置描述。</p>
</td>
<td><p>可选</p></td>
</tr>
</tbody>
</table>
<p>🛠️ <strong>校准参数组</strong></p>
<table class="docutils align-center">
<colgroup>
<col style="width: 4%" />
<col style="width: 21%" />
<col style="width: 67%" />
<col style="width: 8%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>编</p>
<p>号</p>
</th>
<th class="head"><p>参数名称</p></th>
<th class="head"><p>参数配置说明</p></th>
<th class="head"><blockquote>
<div><p>可选/</p>
</div></blockquote>
<p>必选</p>
</th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cal_data_dir</span></code></p></td>
<td><p><strong>参数作用</strong>：指定模型校准使用的标定样本的存放目录。</p>
<p><strong>取值范围</strong>：无。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：目录内校准数据需要符合输入配置的要求，</p>
<p>具体请参考 <a class="reference internal" href="#prepare-calibration-data"><span class="std std-ref">准备校准数据</span></a></p>
<p>部分的介绍。配置多个输入节点时，</p>
<p>设置的节点顺序需要与 <code class="docutils literal notranslate"><span class="pre">input_name</span></code> 里的顺序严格保持一致，</p>
<p>多个值的配置方法请参考前文对 <code class="docutils literal notranslate"><span class="pre">param_value</span></code> 配置描述。</p>
</td>
<td><p>必选</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">preprocess_on</span></code></p></td>
<td><p><strong>参数作用</strong>：开启图片校准样本自动处理。</p>
<p><strong>取值范围</strong>： <code class="docutils literal notranslate"><span class="pre">True</span></code> 、 <code class="docutils literal notranslate"><span class="pre">False</span></code>。</p>
<p><strong>默认配置</strong>： <code class="docutils literal notranslate"><span class="pre">False</span></code>。</p>
<p><strong>参数说明</strong>：在启动该功能时，</p>
<p><cite>cal_data_dir</cite> 目录下存放的都是jpg/bmp/png等图片数据，</p>
<p>工具会使用skimage读取图片，</p>
<p>并resize到输入节点需要的尺寸。</p>
<p>为了保证校准的效果，建议您保持该参数关闭。</p>
<p>使用的影响请参考 <a class="reference internal" href="#prepare-calibration-data"><span class="std std-ref">准备校准数据</span></a></p>
<p>部分的介绍。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">calibration_type</span></code></p></td>
<td><p><strong>参数作用</strong>：校准使用的算法类型。</p>
<p><strong>取值范围</strong>：<code class="docutils literal notranslate"><span class="pre">default</span></code>、 <code class="docutils literal notranslate"><span class="pre">kl</span></code> 、 <code class="docutils literal notranslate"><span class="pre">max</span></code>。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>： <code class="docutils literal notranslate"><span class="pre">kl</span></code> 和 <code class="docutils literal notranslate"><span class="pre">max</span></code> 都是公开的校准量化算法，</p>
<p>其基本原理可以通过网络资料查阅。</p>
<p><code class="docutils literal notranslate"><span class="pre">default</span></code> 是一个自动搜索的策略，</p>
<p>会尝试从系列校准量化参数中获得一个相对效果较好的组合。</p>
<p>建议您先尝试 <code class="docutils literal notranslate"><span class="pre">default</span></code>，</p>
<p>如果最终的精度结果不满足预期</p>
<p>再根据 <a class="reference internal" href="#accuracy-optimization"><span class="std std-ref">精度调优</span></a></p>
<p>部分建议配置不同的校准参数。</p>
</td>
<td><p>必选</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">max_percentile</span></code></p></td>
<td><p><strong>参数作用</strong>：该参数为 <code class="docutils literal notranslate"><span class="pre">max</span></code> 校准方法的参数，</p>
<p>用以调整 <code class="docutils literal notranslate"><span class="pre">max</span></code> 校准的截取点。</p>
<p><strong>取值范围</strong>： <code class="docutils literal notranslate"><span class="pre">0.0</span></code> ~ <code class="docutils literal notranslate"><span class="pre">1.0</span></code>。</p>
<p><strong>默认配置</strong>： <code class="docutils literal notranslate"><span class="pre">1.0</span></code>。</p>
<p><strong>参数说明</strong>：此参数仅在 <code class="docutils literal notranslate"><span class="pre">calibration_type</span></code> 为 <code class="docutils literal notranslate"><span class="pre">max</span></code> 时有效，</p>
<p>常用配置选项有：0.99999/0.99995/0.99990/0.99950/0.99900。</p>
<p>建议您先尝试 <code class="docutils literal notranslate"><span class="pre">calibration_type</span></code> 配置 <code class="docutils literal notranslate"><span class="pre">default</span></code>，</p>
<p>如果最终的精度结果不满足预期</p>
<p>再根据 <a class="reference internal" href="#accuracy-optimization"><span class="std std-ref">精度调优</span></a> 部分建议调整该参数。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">per_channel</span></code></p></td>
<td><p><strong>参数作用</strong>：控制是否针对featuremap的每个channel进行校准。</p>
<p><strong>取值范围</strong>： <code class="docutils literal notranslate"><span class="pre">True</span></code> 、 <code class="docutils literal notranslate"><span class="pre">False</span></code>。</p>
<p><strong>默认配置</strong>： <code class="docutils literal notranslate"><span class="pre">False</span></code>。</p>
<p><strong>参数说明</strong>： <code class="docutils literal notranslate"><span class="pre">calibration_type</span></code> 设置非default时有效。</p>
<p>建议您先尝试 <code class="docutils literal notranslate"><span class="pre">default</span></code>，</p>
<p>如果最终的精度结果不满足预期</p>
<p>再根据 <a class="reference internal" href="#accuracy-optimization"><span class="std std-ref">精度调优</span></a></p>
<p>部分建议调整该参数。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">run_on_cpu</span></code></p></td>
<td><p><strong>参数作用</strong>：强制指定算子在CPU上运行。</p>
<p><strong>取值范围</strong>：无。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：CPU上虽然性能不及BPU，但是提供的是float精度计算，</p>
<p>如果您确定某些算子需要在CPU上计算，</p>
<p>可以通过该参数指定。</p>
<p>设置值为模型中的具体节点名称，</p>
<p>多个值的配置方法请参考前文对 <code class="docutils literal notranslate"><span class="pre">param_value</span></code> 配置描述。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">run_on_bpu</span></code></p></td>
<td><p><strong>参数作用</strong>：强制指定OP在BPU上运行。</p>
<p><strong>取值范围</strong>：无。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：为了保证最终量化模型的精度，少部分情况下，</p>
<p>转换工具会将一些具备BPU计算条件的算子放在CPU上运行。</p>
<p>如果您对性能有较高的要求，愿意以更多一些量化损失为代价，</p>
<p>则可以通过该参数明确指定算子运行在BPU上。</p>
<p>设置值为模型中的具体节点名称，</p>
<p>多个值的配置方法请参考前文对 <code class="docutils literal notranslate"><span class="pre">param_value</span></code> 配置描述。</p>
</td>
<td><p>可选</p></td>
</tr>
</tbody>
</table>
<p>🛠️ <strong>编译参数组</strong></p>
<table class="docutils align-center">
<colgroup>
<col style="width: 4%" />
<col style="width: 20%" />
<col style="width: 69%" />
<col style="width: 8%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>编</p>
<p>号</p>
</th>
<th class="head"><p>参数名称</p></th>
<th class="head"><p>参数配置说明</p></th>
<th class="head"><p>可选/</p>
<p>必选</p>
</th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">compile_mode</span></code></p></td>
<td><p><strong>参数作用</strong>：编译策略选择。</p>
<p><strong>取值范围</strong>： <code class="docutils literal notranslate"><span class="pre">latency</span></code>、 <code class="docutils literal notranslate"><span class="pre">bandwidth</span></code>。</p>
<p><strong>默认配置</strong>： <code class="docutils literal notranslate"><span class="pre">latency</span></code>。</p>
<p><strong>参数说明</strong>： <code class="docutils literal notranslate"><span class="pre">latency</span></code> 以优化推理时间为目标；</p>
<p><code class="docutils literal notranslate"><span class="pre">bandwidth</span></code> 以优化ddr的访问带宽为目标。</p>
<p>如果模型没有严重超过预期的带宽占用，建议您使用 <code class="docutils literal notranslate"><span class="pre">latency</span></code> 策略。</p>
</td>
<td><p>必选</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">debug</span></code></p></td>
<td><p><strong>参数作用</strong>：是否打开编译的debug信息。</p>
<p><strong>取值范围</strong>： <code class="docutils literal notranslate"><span class="pre">True</span></code> 、 <code class="docutils literal notranslate"><span class="pre">False</span></code>。</p>
<p><strong>默认配置</strong>： <code class="docutils literal notranslate"><span class="pre">False</span></code>。</p>
<p><strong>参数说明</strong>：开启该参数情况下，</p>
<p>编译后模型将附带一些调试信息，</p>
<p>用于支持后续的调优分析过程。</p>
<p>默认情况下，建议您保持该参数关闭。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">core_num</span></code></p></td>
<td><p><strong>参数作用</strong>：模型运行核心数。</p>
<p><strong>取值范围</strong>： <code class="docutils literal notranslate"><span class="pre">1</span></code>、 <code class="docutils literal notranslate"><span class="pre">2</span></code>。</p>
<p><strong>默认配置</strong>： <code class="docutils literal notranslate"><span class="pre">1</span></code>。</p>
<p><strong>参数说明</strong>：地平线平台支持利用多个AI加速器核心同时完成一个推理任务，</p>
<p>多核心适用于输入尺寸较大的情况，</p>
<p>理想状态下的双核速度可以达到单核的1.5倍左右。</p>
<p>如果您的模型输入尺寸较大，对于模型速度有极致追求，</p>
<p>可以配置 <code class="docutils literal notranslate"><span class="pre">core_num=2</span></code>。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">optimize_level</span></code></p></td>
<td><p><strong>参数作用</strong>：模型编译的优化等级选择。</p>
<p><strong>取值范围</strong>： <code class="docutils literal notranslate"><span class="pre">O0</span></code> 、 <code class="docutils literal notranslate"><span class="pre">O1</span></code> 、 <code class="docutils literal notranslate"><span class="pre">O2</span></code> 、 <code class="docutils literal notranslate"><span class="pre">O3</span></code>。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：优化等级可选范围为 <code class="docutils literal notranslate"><span class="pre">O0</span></code> ~ <code class="docutils literal notranslate"><span class="pre">O3</span></code>。</p>
<p><code class="docutils literal notranslate"><span class="pre">O0</span></code> 不做任何优化, 编译速度最快，优化程度最低,。</p>
<p><code class="docutils literal notranslate"><span class="pre">O1</span></code> - <code class="docutils literal notranslate"><span class="pre">O3</span></code> 随着优化等级提高，</p>
<p>预期编译后的模型的执行速度会更快，</p>
<p>但是所需编译时间也会变长。</p>
<p>正常用于生产和验证性能的模型，</p>
<p>必须使用 <code class="docutils literal notranslate"><span class="pre">O3</span></code> 级别优化才能保证得到最优性能。</p>
<p>某些流程验证或精度调试过程中，</p>
<p>可以尝试使用更低级别优化加快过程速度。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">input_source</span></code></p></td>
<td><p><strong>参数作用</strong>：设置上板bin模型的输入数据来源。</p>
<p><strong>取值范围</strong>： <code class="docutils literal notranslate"><span class="pre">ddr</span></code>, <code class="docutils literal notranslate"><span class="pre">pyramid</span></code>, <code class="docutils literal notranslate"><span class="pre">resizer</span></code>。</p>
<p><strong>默认配置</strong>： <code class="docutils literal notranslate"><span class="pre">{input_name}</span> <span class="pre">:</span> <span class="pre">ddr</span></code>。</p>
<p><strong>参数说明</strong>：这个参数是适配工程环境的选项，</p>
<p>建议您已经全部完成模型验证后再配置。</p>
<p><code class="docutils literal notranslate"><span class="pre">ddr</span></code> 表示数据来自内存，<code class="docutils literal notranslate"><span class="pre">pyramid</span></code> 和 <code class="docutils literal notranslate"><span class="pre">resizer</span></code></p>
<p>表示来自AI芯片上的固定硬件。</p>
<p>具体在工程环境中如何适配 <code class="docutils literal notranslate"><span class="pre">pyramid</span></code> 和 <code class="docutils literal notranslate"><span class="pre">resizer</span></code> 数据源，</p>
<p>请您参考第4章涉及到的</p>
<p><a class="reference external" href="../bpu_sdk_api_doc/index.html">《BPU SDK API手册》</a>。</p>
<p>此参数配置有点特殊，例如模型输入名称为 data,</p>
<p>数据源为内存(ddr), 则此处应该配置值为 <code class="docutils literal notranslate"><span class="pre">&quot;data&quot;:</span> <span class="pre">&quot;ddr&quot;</span></code>。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">max_time_per_fc</span></code></p></td>
<td><p><strong>参数作用</strong>：指定模型的每个function call的最大可连续执行时间(单位ms)。</p>
<p><strong>取值范围</strong>：<code class="docutils literal notranslate"><span class="pre">0-4294967295</span></code>。</p>
<p><strong>默认配置</strong>：<code class="docutils literal notranslate"><span class="pre">0</span></code>。</p>
<p><strong>参数说明</strong>：编译后的数据指令模型在BPU上进行推理计算时，</p>
<p>它将表现为1个或者多个function-call的调用,</p>
<p>其中function-call是BPU的执行粒度,</p>
<p>该参数用来限制每个function-call最大的执行时间,</p>
<p>设置达到后即使这一段function-call还未执行完也会被高优先级模型抢占。</p>
<p>当一个模型设置了 <code class="docutils literal notranslate"><span class="pre">max_time_per_fc</span></code> 编译参数后，即为低优先级模型，</p>
<p>它才可以被抢占。</p>
<p>详情参见 <a class="reference internal" href="chapter_4_application_development.html#preemption"><span class="std std-ref">模型优先级控制</span></a> 部分的介绍。</p>
</td>
<td><p>可选</p></td>
</tr>
</tbody>
</table>
<p>🛠️ <strong>自定义算子参数组</strong></p>
<table class="docutils align-center">
<colgroup>
<col style="width: 4%" />
<col style="width: 24%" />
<col style="width: 63%" />
<col style="width: 9%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>编
号</p></th>
<th class="head"><p>参数名称</p></th>
<th class="head"><p>参数配置说明</p></th>
<th class="head"><p>可选/</p>
<p>必选</p>
</th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">custom_op_method</span></code></p></td>
<td><p><strong>参数作用</strong>：自定义算子策略选择。</p>
<p><strong>取值范围</strong>：<code class="docutils literal notranslate"><span class="pre">register</span></code>。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：目前仅支持register策略，具体使用请参考</p>
<p><a class="reference internal" href="chapter_5_custom_op_development.html"><span class="doc">自定义算子开发</span></a>。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">op_register_files</span></code></p></td>
<td><p><strong>参数作用</strong>：自定义算子的Python实现文件名称。</p>
<p><strong>取值范围</strong>：无。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：多个文件可用 <code class="docutils literal notranslate"><span class="pre">;</span></code> 分隔，算子如何实现请参考</p>
<p><a class="reference internal" href="chapter_5_custom_op_development.html"><span class="doc">自定义算子开发</span></a>。</p>
</td>
<td><p>可选</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">custom_op_dir</span></code></p></td>
<td><p><strong>参数作用</strong>：自定义算子的Python实现文件存放路径。</p>
<p><strong>取值范围</strong>：无。</p>
<p><strong>默认配置</strong>：无。</p>
<p><strong>参数说明</strong>：设置路径时，请使用相对路径。</p>
</td>
<td><p>可选</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="conversion-interpretation">
<span id="id9"></span><h3><span class="section-number">3.4.2. </span>转换内部过程解读<a class="headerlink" href="#conversion-interpretation" title="永久链接至标题">¶</a></h3>
<p>模型转换完成浮点模型到地平线混合异构模型的转换。
为了使得这个异构模型能快速高效地在嵌入式端运行，
模型转换重点在解决 <strong>输入数据处理</strong> 和 <strong>模型优化编译</strong> 两个问题，本节会依次围绕这两个重点问题展开。</p>
<p><strong>输入数据处理</strong> 方面地平线的边缘AI计算平台会为某些特定类型的输入通路提供硬件级的支撑方案，
但是这些方案的输出不一定符合模型输入的要求。
例如视频通路方面就有视频处理子系统，为采集提供图像裁剪、缩放和其他图像质量优化功能，这些子系统的输出往往是yuv420格式图像，
而我们的算法模型往往是基于bgr/rgb等一般常用图像格式训练得到的。
地平线针对此种情况提供的固定解决方案是，每个转换模型都提供两份输入信息描述，
一份用于描述原始浮点模型输入（<code class="docutils literal notranslate"><span class="pre">input_type_train</span></code> 和 <code class="docutils literal notranslate"><span class="pre">input_layout_train</span></code>），
另一份则用于描述我们需要对接的边缘平台输入数据（<code class="docutils literal notranslate"><span class="pre">input_type_rt</span></code> 和 <code class="docutils literal notranslate"><span class="pre">input_layout_rt</span></code>）。</p>
<p>图像数据的mean/scale也是比较常见的操作，显然yuv420等边缘平台数据格式不再适合做这样的操作，
因此，我们也将这些常见图像前处理固化到了模型中。
经过以上两种处理后，转换产出的异构模型的输入部分将变成如下图状态。</p>
<a class="reference internal image-reference" href="_images/input_data_process.png"><img alt="_images/input_data_process.png" class="align-center" src="_images/input_data_process.png" style="width: 899.2px; height: 229.60000000000002px;" /></a>
<p>上图中的数据排布就只有NCHW和NHWC两种数据排布格式，N代表数量、C代表channel、H代表高度、W代表宽度，
两种不同的排布体现的是不同的内存访问特性。在TensorFlow模型NHWC较常用，Caffe中就都使用NCHW，
地平线平台不会限制使用的数据排布，但是有两条要求：第一是 <code class="docutils literal notranslate"><span class="pre">input_layout_train</span></code> 必须与原始模型的数据排布一致；
第二是在边缘AI平台准备好与 <code class="docutils literal notranslate"><span class="pre">input_layout_rt</span></code> 一致排布的数据，正确的数据排布指定是顺利解析数据的基础。</p>
<p>工具会根据 <code class="docutils literal notranslate"><span class="pre">input_type_rt</span></code> 和 <code class="docutils literal notranslate"><span class="pre">input_type_train</span></code> 指定的数据格式自动添加数据转换节点，根据地平线的实际生产经验，
并不是任意type组合都是需要的，为了避免您误用，我们只开放了一些固定的type组合如下表。</p>
<table class="docutils align-center">
<colgroup>
<col style="width: 28%" />
<col style="width: 10%" />
<col style="width: 14%" />
<col style="width: 9%" />
<col style="width: 9%" />
<col style="width: 10%" />
<col style="width: 21%" />
</colgroup>
<tbody>
<tr class="row-odd"><td></td>
<td><p>nv12</p></td>
<td><p>yuv444</p></td>
<td><p>rgb</p></td>
<td><p>bgr</p></td>
<td><p>gray</p></td>
<td><p>featuremap</p></td>
</tr>
<tr class="row-even"><td><p><strong>yuv444</strong></p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
<td><p>N</p></td>
<td><p>N</p></td>
<td><p>N</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p><strong>rgb</strong></p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
<td><p>N</p></td>
<td><p>N</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p><strong>bgr</strong></p></td>
<td><p>Y</p></td>
<td><p>Y</p></td>
<td><p>N</p></td>
<td><p>Y</p></td>
<td><p>N</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p><strong>gray</strong></p></td>
<td><p>N</p></td>
<td><p>N</p></td>
<td><p>N</p></td>
<td><p>N</p></td>
<td><p>Y</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p><strong>featuremap</strong></p></td>
<td><p>N</p></td>
<td><p>N</p></td>
<td><p>N</p></td>
<td><p>N</p></td>
<td><p>N</p></td>
<td><p>Y</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>表格中第一行是 <code class="docutils literal notranslate"><span class="pre">input_type_rt</span></code> 中支持的类型，第一列是 <code class="docutils literal notranslate"><span class="pre">input_type_train</span></code> 支持的类型，
其中的 <strong>Y/N</strong> 表示是否支持相应的 <code class="docutils literal notranslate"><span class="pre">input_type_rt</span></code> 到 <code class="docutils literal notranslate"><span class="pre">input_type_train</span></code> 的转换。
在转换得到的最终产出bin模型中，<code class="docutils literal notranslate"><span class="pre">input_type_rt</span></code> 到 <code class="docutils literal notranslate"><span class="pre">input_type_train</span></code> 是一个内部的过程，
您只需要关注 <code class="docutils literal notranslate"><span class="pre">input_type_rt</span></code> 的数据格式即可。
<strong>正确理解每种</strong> <code class="docutils literal notranslate"><span class="pre">input_type_rt</span></code> <strong>的要求，对于嵌入式应用准备推理数据很重要，以下是对</strong>
<code class="docutils literal notranslate"><span class="pre">input_type_rt</span></code> <strong>每种格式的说明：</strong></p>
<blockquote>
<div><ul class="simple">
<li><p>rgb、bgr和gray都是比较常见的图像数据，注意每个数值都采用UINT8表示。</p></li>
<li><p>yuv444是一种常见的图像格式，注意每个数值都采用UINT8表示。</p></li>
<li><p>nv12是常见的yuv420图像数据，每个数值都采用UINT8表示。</p></li>
<li><p>nv12有个比较特别的情况是 <code class="docutils literal notranslate"><span class="pre">input_space_and_range</span></code> 设置 <code class="docutils literal notranslate"><span class="pre">bt601_video</span></code>
（参考前文对 <code class="docutils literal notranslate"><span class="pre">input_space_and_range</span></code> 参数的介绍），较于常规nv12情况，它的数值范围由[0,255]变成了[16,235]，
每个数值仍然采用UINT8表示。</p></li>
<li><p>featuremap适用于以上列举格式不满足您需求的情况，此type只要求您的数据是四维的，每个数值采用float32表示。
例如雷达和语音等模型处理就常用这个格式。</p></li>
</ul>
</div></blockquote>
</div>
<div class="admonition tip">
<p class="admonition-title">小技巧</p>
<p>以上 <code class="docutils literal notranslate"><span class="pre">input_type_rt</span></code> 与 <code class="docutils literal notranslate"><span class="pre">input_type_train</span></code> 是固化在工具链的处理流程中，如果您非常确定不需要转换，
将两个 <code class="docutils literal notranslate"><span class="pre">input_type</span></code> 设置成一样就可以了，一样的 <code class="docutils literal notranslate"><span class="pre">input_type</span></code> 会做直通处理，不会影响模型的实际执行性能。</p>
<p>同样的，数据前处理也是固化在流程中，如果您不需要做任何前处理，通过 <code class="docutils literal notranslate"><span class="pre">norm_type</span></code> 配置关闭这个功能即可，不会影响模型的实际执行性能。</p>
</div>
<p><strong>模型优化编译</strong> 方面完成了模型解析、模型优化、模型校准与量化、模型编译几个重要阶段，其内部工作过程如下图所示。</p>
<a class="reference internal image-reference" href="_images/model_optimization.png"><img alt="_images/model_optimization.png" class="align-center" src="_images/model_optimization.png" style="width: 896.0px; height: 515.1999999999999px;" /></a>
<p>模型解析阶段 对于Caffe浮点模型会完成到ONNX浮点模型的转换。
在原始浮点模型上会根据转换配置中的配置参数决定是否加入数据预处理节点，此阶段产出一个original_float_model.onnx。
这个ONNX模型计算精度仍然是float32，在输入部分加入了一个数据预处理节点。</p>
<p>理想状态下，这个预处理节点应该完成 <code class="docutils literal notranslate"><span class="pre">input_type_rt</span></code> 到 <code class="docutils literal notranslate"><span class="pre">input_type_train</span></code> 的完整转换，
实际情况是整个type转换过程会配合地平线AI芯片硬件完成，ONNX模型里面并没有包含硬件转换的部分。
因此ONNX的真实输入类型会使用一种中间类型，这种中间类型就是硬件对 <code class="docutils literal notranslate"><span class="pre">input_type_rt</span></code> 的处理结果类型，
数据layout(NCHW/NHWC)会保持原始浮点模型的输入layout一致。
每种 <code class="docutils literal notranslate"><span class="pre">input_type_rt</span></code> 都有特定的对应中间类型，如下表：</p>
<table class="docutils align-center">
<colgroup>
<col style="width: 19%" />
<col style="width: 19%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 16%" />
<col style="width: 19%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>nv12</strong></p></td>
<td><p><strong>yuv444</strong></p></td>
<td><p><strong>rgb</strong></p></td>
<td><p><strong>bgr</strong></p></td>
<td><p><strong>gray</strong></p></td>
<td><p>featuremap</p></td>
</tr>
<tr class="row-even"><td><p>yuv444_128</p></td>
<td><p>yuv444_128</p></td>
<td><p>RGB_128</p></td>
<td><p>BGR_128</p></td>
<td><p>GRAY_128</p></td>
<td><p>featuremap</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>表格中第一行加粗部分是 <code class="docutils literal notranslate"><span class="pre">input_type_rt</span></code> 指定的数据类型，第二行是特定 <code class="docutils literal notranslate"><span class="pre">input_type_rt</span></code> 对应的中间类型，
这个中间类型就是original_float_model.onnx的输入类型。每个类型解释如下：</p>
<ul class="simple">
<li><p>yuv444_128 是yuv444数据减去128结果，每个数值采用float32表示。</p></li>
<li><p>RGB_128 是RGB数据减去128的结果，每个数值采用float32表示。</p></li>
<li><p>BGR_128 是BGR数据减去128的结果，每个数值采用float32表示。</p></li>
<li><p>GRAY_128 是gray数据减去128的结果，每个数值采用float32表示。</p></li>
<li><p>featuremap 是一个四维张量数据，每个数值采用float32表示。</p></li>
</ul>
</div>
<p><strong>模型优化阶段</strong> 实现模型的一些适用于地平线平台的算子优化策略，例如BN融合到Conv等。
此阶段的产出是一个optimized_float_model.onnx，这个ONNX模型的计算精度仍然是float32，经过优化后不会影响模型的计算结果。
模型的输入数据要求还是与前面的original_float_model一致。</p>
<p><strong>模型校准阶段</strong> 会使用您提供的校准数据来计算必要的量化阈值参数，这些参数会直接输入到量化阶段，不会产生新的模型状态。</p>
<p>模型量化阶段 使用校准得到的参数完成模型量化，此阶段的产出是一个quantized_model.onnx。
这个模型的输入计算精度已经是int8，使用这个模型可以评估到模型量化带来的精度损失情况。
这个模型要求输入的基本数据格式仍然与 <code class="docutils literal notranslate"><span class="pre">original_float_model</span></code> 一样，不过layout已经和数值表示发生了变化，
整体较于 <code class="docutils literal notranslate"><span class="pre">original_float_model</span></code> 输入的变化情况描述如下：</p>
<ul class="simple">
<li><p>数据layout均使用NHWC。</p></li>
<li><p>当使用中间类型不是featuremap时，数值表示均使用INT8，featuremap仍然使用float32表示。</p></li>
</ul>
<p><strong>模型编译阶段</strong> 会使用地平线模型编译器，将量化模型转换为地平线平台支持的计算指令和数据，
这个阶段的产出一个***.bin模型，这个bin模型是后续将在地平线边缘嵌入式平台运行的模型，也就是模型转换的最终产出结果。</p>
</div>
<div class="section" id="prepare-calibration-data">
<span id="id10"></span><h3><span class="section-number">3.4.3. </span>准备校准数据<a class="headerlink" href="#prepare-calibration-data" title="永久链接至标题">¶</a></h3>
<p>在进行模型转换时，校准阶段会需要100份左右标定样本输入，每一份样本都是一个独立的数据文件。
为了确保转换后模型的精度效果，我们希望这些校准样本来自于您训练模型使用的训练集或验证集，
不要使用非常少见的异常样本，例如纯色图片、不含任何检测或分类目标的图片等。</p>
<p>前文介绍了转换配置文件中的 <code class="docutils literal notranslate"><span class="pre">preprocess_on</span></code> 参数，该参数启用和关闭状态下分别对应了两种不同的预处理样本要求。</p>
<p><code class="docutils literal notranslate"><span class="pre">preprocess_on</span></code> 关闭状态下，您需要把取自训练集/验证集的样本做与inference前一样的前处理，
处理完后的校准样本会与原始模型具备一样的数据类型(前文 <code class="docutils literal notranslate"><span class="pre">input_type_train</span></code>)、尺寸(前文 <code class="docutils literal notranslate"><span class="pre">input_shape</span></code>)和
layout(前文 <code class="docutils literal notranslate"><span class="pre">input_layout_train</span></code>)，将这些样本逐一按二进制存储为独立文件即可。
例如，有一个使用ImageNet训练的用于分类的原始浮点模型，它只有一个输入节点，输入信息描述如下：</p>
<ul class="simple">
<li><p>输入类型：<code class="docutils literal notranslate"><span class="pre">BGR</span></code></p></li>
<li><p>输入layout：<code class="docutils literal notranslate"><span class="pre">NCHW</span></code></p></li>
<li><p>输入尺寸：<code class="docutils literal notranslate"><span class="pre">1x3x224x224</span></code></p></li>
</ul>
<p>使用验证集做Inference时的数据预处理如下：</p>
<ol class="arabic simple">
<li><p>图像长宽等比scale,短边缩放到256。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">center_crop</span></code> 方法获取224x224大小图像。</p></li>
<li><p>按通道减mean</p></li>
<li><p>数据乘以scale系数</p></li>
</ol>
<p>依照 <code class="docutils literal notranslate"><span class="pre">preprocess_on</span></code> 关闭状态下的样本文件制作原则，针对上述举例模型的样本处理代码如下
(为避免过长代码篇幅，各种简单transformer实现代码未贴出，请自行实现)：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span># 本示例使用skimage，如果是opencv会有所区别
# 需要您特别注意的是，transformers中并没有体现减mean和乘scale的处理
# mean和scale操作已经融合到了模型中，参考前文norm_type/mean_values/scale_values配置
def data_transformer():
  transformers = [
  # 长宽等比scale，短边缩放至256
  ShortSideResizeTransformer(short_size=256),
  # CenterCrop获取224x224图像
  CenterCropTransformer(crop_size=224),
  # skimage读取结果为NHWC排布，转换为模型需要的NCHW
  HWC2CHWTransformer(),
  # skimage读取结果通道顺序为RGB，转换为模型需要的BGR
  RGB2BGRTransformer(),
  # skimage读取数值范围为[0.0,1.0]，调整为模型需要的数值范围
  ScaleTransformer(scale_value=255)
  ]

  return transformers

# src_image 标定集中的原图片
# dst_file 存放最终标定样本数据的文件名称
def convert_image(src_image, dst_file, transformers)：
  image = skimage.img_as_float(skimage.io.imread(src_file))
  for trans in transformers:
  image = trans(image)
  # 模型指定的input_type_train BGR数值类型是UINT8
  image = image.astype(np.uint8)
  # 二进制存储标定样本到数据文件
  image.tofile(dst_file)

if __name__ == &#39;__main__&#39;:
  # 此处表示原始标定图片集合，伪代码
  src_images = [&#39;ILSVRC2012_val_00000001.JPEG&#39;，...]
  # 此处表示最终标定文件名称（后缀名不限制），伪代码
  # calibration_data_bgr是您在配置文件中指定的cal_data_dir
  dst_files = [&#39;./calibration_data_bgr/ILSVRC2012_val_00000001.bgr&#39;，...]

  transformers = data_transformer()
  for src_image, dst_file in zip(src_images, dst_files):
  convert_image(src_image, dst_file, transformers)
</pre></div>
</div>
<div class="admonition tip">
<p class="admonition-title">小技巧</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">preprocess_on</span></code> 启用状态下，标定样本使用skimage支持read的图片格式文件即可。</dt><dd><p>转换工具读取这些图片后，会将其缩放到模型输入节点要求的尺寸大小，以此结果作为校准的输入。
这样的操作会简单，但是对于量化精度的没有保障，我们强烈建议您使用前文关闭 <code class="docutils literal notranslate"><span class="pre">preprocess_on</span></code> 的方式。</p>
</dd>
</dl>
</div>
</div>
<div class="section" id="id11">
<h3><span class="section-number">3.4.4. </span>转换结果解读<a class="headerlink" href="#id11" title="永久链接至标题">¶</a></h3>
<p>本节将依次介绍模型转换成功状态的解读、转换不成功的分析方式。
确认模型转换成功，需要您从 <code class="docutils literal notranslate"><span class="pre">makertbin</span></code> 状态信息、相似度信息和 <cite>working_dir</cite> 产出三个方面确认。
<code class="docutils literal notranslate"><span class="pre">makertbin</span></code> 状态信息方面，转换成功将在控制台输出信息尾部给出明确的提示信息如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="m">2021</span>-04-21 <span class="m">11</span>:13:08,337 INFO Convert to runtime bin file successfully!
<span class="m">2021</span>-04-21 <span class="m">11</span>:13:08,337 INFO End Model Convert
</pre></div>
</div>
<p>相似度信息也存在于 <code class="docutils literal notranslate"><span class="pre">makertbin</span></code> 的控制台输出内容中，在 <code class="docutils literal notranslate"><span class="pre">makertbin</span></code> 状态信息之前，其内容形式如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">======================================================================</span>
Node    ON   Subgraph  Type     Cosine Similarity  Threshold
----------------------------------------------------------------------
...    ...     ...     ...       <span class="m">0</span>.999936           <span class="m">127</span>.000000
...    ...     ...     ...       <span class="m">0</span>.999868           <span class="m">2</span>.557209
...    ...     ...     ...       <span class="m">0</span>.999268           <span class="m">2</span>.133924
...    ...     ...     ...       <span class="m">0</span>.996023           <span class="m">3</span>.251645
...    ...     ...     ...       <span class="m">0</span>.996656           <span class="m">4</span>.495638
</pre></div>
</div>
<p>上面列举的输出内容中，Node、ON、Subgraph、Type与 <code class="docutils literal notranslate"><span class="pre">hb_mapper</span> <span class="pre">checker</span></code> 工具的解读是一致的，
请参考前文 <a class="reference internal" href="#check-result"><span class="std std-ref">检查结果解读</span></a>；
Threshold是每个层次的校准阈值，用于异常状态下向地平线技术支持反馈信息，正常状况下不需要关注；
Cosine Similarity反映的Node指示的节点中，原始浮点模型与量化模型输出结果的余弦相似度。</p>
<div class="admonition attention">
<p class="admonition-title">注意</p>
<p>需要您特别注意的是，Cosine Similarity只是指明量化后数据稳定性的一种参考方式，对于模型精度的影响不存在明显的直接关联关系。
一般情况下，输出节点的相似度低于0.8就有了较明显的精度损失，当然由于与精度不存在绝对的直接关联，
完全准确的精度情况还需要您参考 <a class="reference internal" href="#accuracy-evaluation"><span class="std std-ref">模型精度分析与调优</span></a> 的介绍。</p>
</div>
<p>转换产出存放在转换配置参数 <code class="docutils literal notranslate"><span class="pre">working_dir</span></code> 指定的路径中，成功完成模型转换后，
您可以在该目录下得到以下文件(***部分是您通过转换配置参数 <code class="docutils literal notranslate"><span class="pre">output_model_file_prefix</span></code> 指定的内容)：</p>
<ul class="simple">
<li><p>***_{input_size}_{input_type}_original_float_model.onnx</p></li>
<li><p>***_{input_size}_{input_type}_optimized_float_model.onnx</p></li>
<li><p>***_{input_size}_{input_type}_quantized_model.onnx</p></li>
<li><p>***_{input_size}_{input_type}.bin</p></li>
</ul>
<p><a class="reference internal" href="#conversion-output"><span class="std std-ref">转换产出物解读</span></a> 介绍了每个产出物的用途。
不过在上板运行前，我们强烈建议您完成 <a class="reference internal" href="#model-check"><span class="std std-ref">检查模型</span></a> 和 <a class="reference internal" href="#performance-evaluation"><span class="std std-ref">模型性能分析与调优</span></a>
介绍的性能&amp;精度评测过程，避免将模型转换问题延伸到后续嵌入式端。</p>
<p>如果以上检查模型转换成功的三个方面中，有任一个出现缺失都说明模型转换出现了错误。
一般情况下，<code class="docutils literal notranslate"><span class="pre">makertbin</span></code> 工具会在出现错误时将错误信息输出至控制台，
例如我们在Caffe模型转换时不配置 <code class="docutils literal notranslate"><span class="pre">prototxt</span></code> 和 <code class="docutils literal notranslate"><span class="pre">caffe_model</span></code> 参数，工具给出如下提示。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="m">2021</span>-04-21 <span class="m">14</span>:45:34,085 ERROR Key <span class="s1">&#39;model_parameters&#39;</span> error:
Missing keys: <span class="s1">&#39;caffe_model&#39;</span>, <span class="s1">&#39;prototxt&#39;</span>
<span class="m">2021</span>-04-21 <span class="m">14</span>:45:34,085 ERROR yaml file parse failed. Please double check your input
<span class="m">2021</span>-04-21 <span class="m">14</span>:45:34,085 ERROR exception in command: makertbin
</pre></div>
</div>
<p>如果转换工具控制台输出信息未能明确指示问题所在，此时需要您在转换配置文件中将前文介绍的 <code class="docutils literal notranslate"><span class="pre">log_level</span></code> 参数设置为 <code class="docutils literal notranslate"><span class="pre">debug</span></code> 级别，
重新做转换后，您可以在当前工作目录下hb_mapper_makertbin.log中看到导致错误发生的原因。</p>
<p>如果以上两步仍不能帮助您发现问题，欢迎在地平线唯一官方技术社区（<a class="reference external" href="https://developer.horizon.ai/">https://developer.horizon.ai/</a>）提出您的问题，
我们将在24小时内给您提供支持。</p>
</div>
<div class="section" id="conversion-output">
<span id="id12"></span><h3><span class="section-number">3.4.5. </span>转换产出物解读<a class="headerlink" href="#conversion-output" title="永久链接至标题">¶</a></h3>
<p>上文提到模型成功转换的产出物包括以下四个部分，本节将介绍每个产出物的用途：</p>
<ul class="simple">
<li><p>***_{input_size}_{input_type}_original_float_model.onnx</p></li>
<li><p>***_{input_size}_{input_type}_optimized_float_model.onnx</p></li>
<li><p>***_{input_size}_{input_type}_quantized_model.onnx</p></li>
<li><p>***_{input_size}_{input_type}.bin</p></li>
</ul>
<p>***_{input_size}_{input_type}_original_float_model.onnx的产出过程可以参考 <a class="reference internal" href="#conversion-interpretation"><span class="std std-ref">转换内部过程解读</span></a> 的介绍，
这个模型计算精度与转换输入的原始浮点模型是一模一样的，有个重要的变化就是为了适配地平线平台添加了一些数据预处理计算。
一般情况下，您不需要使用这个模型，在转换结果出现异常时，如果能把这个模型提供给地平线的技术支持，将有助于帮助您快速解决问题。</p>
<p>***_{input_size}_{input_type}_optimized_float_model.onnx的产出过程可以参考 <a class="reference internal" href="#conversion-interpretation"><span class="std std-ref">转换内部过程解读</span></a> 的介绍，
这个模型经过一些算子级别的优化操作，常见的就是算子融合。
通过与original_float模型的可视化对比，您可以明显看到一些算子结构级别的变化，不过这些都不影响模型的计算精度。
一般情况下，您不需要使用这个模型，在转换结果出现异常时，如果能把这个模型提供给地平线的技术支持，将有助于帮助您快速解决问题。</p>
<p>***_{input_size}_{input_type}_quantized_model.onnx的产出过程可以参考 <a class="reference internal" href="#conversion-interpretation"><span class="std std-ref">转换内部过程解读</span></a> 的介绍，
这个模型已经完成了校准和量化过程，量化后的精度损失情况可以从这里查看。
这个模型是精度验证过程中必须要使用的模型，具体使用方式请参考 <a class="reference internal" href="#accuracy-evaluation"><span class="std std-ref">模型精度分析与调优</span></a> 部分的介绍。</p>
<p>***_{input_size}_{input_type}.bin就是可以用于在地平线AI芯片上加载运行的模型，
配合 <a class="reference internal" href="chapter_4_application_development.html"><span class="doc">第4章：应用开发</span></a> 部分介绍的内容，
您就可以将模型快速在芯片部署运行。不过为了确保模型的性能与精度效果是符合您的预期的，
我们强烈建议完成 <a class="reference internal" href="#model-conversion"><span class="std std-ref">转换模型</span></a> 和 <a class="reference internal" href="#accuracy-evaluation"><span class="std std-ref">模型精度分析与调优</span></a>
介绍的性能和精度分析过程后再进入到应用开发和部署。</p>
</div>
</div>
<div class="section" id="performance-evaluation">
<span id="id13"></span><h2><span class="section-number">3.5. </span>模型性能分析与调优<a class="headerlink" href="#performance-evaluation" title="永久链接至标题">¶</a></h2>
<p>本节介绍了如何使用地平线提供的工具评估模型性能，这些工具得到的都是与实际执行基本无异的性能效果，
如果此阶段发现评估结果不符合预期，强烈建议您尽量在此阶段根据地平线的优化建议解决性能问题，
不建议将模型的问题延伸到应用开发阶段。</p>
<div class="section" id="hb-perf">
<span id="id14"></span><h3><span class="section-number">3.5.1. </span>使用 <code class="docutils literal notranslate"><span class="pre">hb_perf</span></code> 工具估计性能<a class="headerlink" href="#hb-perf" title="永久链接至标题">¶</a></h3>
<p>地平线提供的 <code class="docutils literal notranslate"><span class="pre">hb_perf</span></code> 以模型转换得到的 ***_{input_size}_{input_type}.bin为输入，可以直接得到模型预期上板性能，工具使用方式如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hb_perf  ***.bin
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>如果分析的是 <code class="docutils literal notranslate"><span class="pre">pack</span></code> 后模型，需要加上一个 <code class="docutils literal notranslate"><span class="pre">-p</span></code> 参数，命令为 <code class="docutils literal notranslate"><span class="pre">hb_perf</span> <span class="pre">-p</span> <span class="pre">***.bin</span></code>。
关于模型 <code class="docutils literal notranslate"><span class="pre">pack</span></code>，请查看 <a class="reference internal" href="#other-tools"><span class="std std-ref">其他模型工具（可选）</span></a> 部分的介绍。</p>
</div>
<p>命令中的 ***.bin就是模型转换产出的bin模型，命令执行完成后，
在当前工作目录下会得到一个 <cite>hb_perf_result</cite> 目录，分析结果以html形式提供。
以下是我们分析一个MobileNet的示例结果，其中mobilenetv1_224x224_nv12.html就是查看分析结果的主页面。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hb_perf_result/
└── mobilenetv1_224x224_nv12
    ├── MOBILENET_subgraph_0.html
    ├── MOBILENET_subgraph_0.json
    ├── mobilenetv1_224x224_nv12
    ├── mobilenetv1_224x224_nv12.html
    ├── mobilenetv1_224x224_nv12.png
    └── temp.hbm
</pre></div>
</div>
<p>通过浏览器打开结果主页面，其内容如下图：</p>
<img alt="_images/model_perf_report.png" class="align-center" src="_images/model_perf_report.png" />
<p>分析结果主要由Model Performance Summary、Details和BIN Model Structure三个部分组成。
Model Performance Summary是整个bin模型的整体性能评估结果，其中各项指标为:</p>
<ul class="simple">
<li><p>Model Name——模型名称。</p></li>
<li><p>Model Latency(ms)——模型整体单帧计算耗时(单位为ms)。</p></li>
<li><p>Model Frame Rate(fps)——模型整体帧率(单位为fps)。</p></li>
<li><p>Model DDR Occupation(Mb per frame)——模型运行的整体内存占用情况(单位为Mb/frame)。</p></li>
<li><p>Loaded Bytes per Frame——模型运行每帧读取数据量。</p></li>
<li><p>Stored Bytes per Frame——模型运行每帧存储数据量。</p></li>
</ul>
<p>在了解Details和BIN Model Structure前，您需要了解子图（subgraph）的概念。
如果模型在非输入和输出部分出现了CPU计算的算子，模型转换工具将把这个算子前后连续在BPU计算的部分拆分为两个独立的子图（subgraph）。
具体可以参考 <a class="reference internal" href="#model-check"><span class="std std-ref">检查模型</span></a> 部分的介绍。</p>
<p>Details是每份模型BPU子图的具体信息，在主页面中，每个子图提供的指标解读如下：</p>
<ul class="simple">
<li><p>Model Subgraph Name——子图名称。</p></li>
<li><p>Model Subgraph Calculation Load (OPpf)——子图的单帧计算量。</p></li>
<li><p>Model Subgraph DDR Occupation(Mbpf)——子图的单帧读写数据量（单位为MB）。</p></li>
<li><p>Model Subgraph Latency(ms)——子图的单帧计算耗时（单位为ms）。</p></li>
</ul>
<p>每份子图结果提供了一个明细入口，以上指标都是明细页面提取到的，进入到明细页面可以给您更加细致的参考信息。</p>
<div class="admonition attention">
<p class="admonition-title">注意</p>
<p>需要特别注意的是，明细页面会根据您是否启用调试级转换而有所区别，
下图中的Layer Details仅当在配置文件中设置 <code class="docutils literal notranslate"><span class="pre">debug</span></code> 参数为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 时才可以拿到，
这个 <code class="docutils literal notranslate"><span class="pre">debug</span></code> 参数配置方法请参考 <a class="reference internal" href="#makertbin"><span class="std std-ref">使用 hb_mapper makertbin 工具转换模型</span></a> 部分的介绍。</p>
</div>
<p>Layer Details提供到了具体算子级别的分析，在调试分析阶段也是比较不错的参考，
如果是某些BPU算子导致性能低，可以帮助您定位到这个具体算子。</p>
<img alt="_images/layer_details.png" class="align-center" src="_images/layer_details.png" />
<p>BIN Model Structure部分提供的是bin模型的子图级可视化结果，图中深色节点表示运行在BPU上的子图，灰色节点表示在CPU上计算的节点。</p>
<p>使用 <code class="docutils literal notranslate"><span class="pre">hb_perf</span></code> 的意义在于了解bin模型子图结构，对于BPU上计算部分，该工具也能提供较全面的静态分析指标。
不过 <code class="docutils literal notranslate"><span class="pre">hb_perf</span></code> 不含CPU部分的计算评估，如果CPU计算仅限于模型输入或输出部分的常规性处理，不含计算密集型计算节点，这个影响不大。
否则，您就一定需要利用开发板工具实测性能。</p>
</div>
<div class="section" id="id15">
<h3><span class="section-number">3.5.2. </span>开发板实测性能<a class="headerlink" href="#id15" title="永久链接至标题">¶</a></h3>
<p>开发板上实测模型性能使用的是开发板上 <code class="docutils literal notranslate"><span class="pre">hrt_model_exec</span> <span class="pre">perf</span></code> 工具，
<code class="docutils literal notranslate"><span class="pre">hrt</span> <span class="pre">_model_exec</span></code> 是一个模型执行工具，可直接在开发板上评测模型的推理性能、获取模型信息。
一方面可以让用户拿到模型时实际了解模型真实性能；
另一方面也可以帮助用户了解模型可以做到的速度极限，对于应用调优的目标极限具有指导意义。</p>
<p>使用 <code class="docutils literal notranslate"><span class="pre">hrt_model_exec</span> <span class="pre">perf</span></code> 工具前，有两个准备工作。</p>
<ol class="arabic simple">
<li><p>确保您已经参考 <a class="reference internal" href="chapter_2_prerequisites.html"><span class="doc">第2章：环境部署</span></a> 介绍完成了开发板上工具安装。</p></li>
<li><p>第二是需要将Ubuntu/CentOS开发机上得到的bin模型拷贝到开发板上（建议放在/userdata目录），
开发板上是一个Linux系统，可以通过 <code class="docutils literal notranslate"><span class="pre">scp</span></code> 等Linux系统常用方式完成这个拷贝过程。</p></li>
</ol>
<p>使用 <code class="docutils literal notranslate"><span class="pre">hrt_model_exec</span> <span class="pre">perf</span></code> 实测性能的参考命令如下（<strong>注意是在开发板上执行</strong>）：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./hrt_model_exec perf --model_file mobilenetv1_224x224_nv12.bin <span class="se">\</span>
                      --model_name<span class="o">=</span><span class="s2">&quot;&quot;</span> <span class="se">\</span>
                      --core_id<span class="o">=</span><span class="m">0</span> <span class="se">\</span>
                      --frame_count<span class="o">=</span><span class="m">200</span> <span class="se">\</span>
                      --perf_time<span class="o">=</span><span class="m">0</span> <span class="se">\</span>
                      --thread_num<span class="o">=</span><span class="m">1</span> <span class="se">\</span>
                      --profile_path<span class="o">=</span><span class="s2">&quot;.&quot;</span>
</pre></div>
</div>
<dl class="py data">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">hrt_model_exec</span> <span class="pre">perf</span></span></dt>
<dd><dl class="simple">
<dt>model_file：</dt><dd><p>需要分析性能的bin模型名称。</p>
</dd>
<dt>model_name:</dt><dd><p>需要分析性能的bin模型名字。若 <code class="docutils literal notranslate"><span class="pre">model_file</span></code> 只含一个模型，则可以省略。</p>
</dd>
<dt>core_id</dt><dd><p>默认值 <code class="docutils literal notranslate"><span class="pre">0</span></code>，运行模型使用的核心id，<code class="docutils literal notranslate"><span class="pre">0</span></code> 代表任意核心，<code class="docutils literal notranslate"><span class="pre">1</span></code> 代表核心0，<code class="docutils literal notranslate"><span class="pre">2</span></code> 代表核心1。若要分析双核极限帧率，请将此处设为 <code class="docutils literal notranslate"><span class="pre">0</span></code>。</p>
</dd>
<dt>frame_count：</dt><dd><p>默认值 <code class="docutils literal notranslate"><span class="pre">200</span></code>，设置推理帧数，工具会执行指定次数后再分析平均耗时。 当 <code class="docutils literal notranslate"><span class="pre">perf_time</span></code> 为 <code class="docutils literal notranslate"><span class="pre">0</span></code> 时生效。</p>
</dd>
<dt>perf_time:</dt><dd><p>默认值 <code class="docutils literal notranslate"><span class="pre">0</span></code>，单位分钟。设置推理时间，工具会执行指定时间后再分析平均耗时。</p>
</dd>
<dt>thread_num：</dt><dd><p>默认值 <code class="docutils literal notranslate"><span class="pre">1</span></code>，设置运行的线程数，取值范围 <code class="docutils literal notranslate"><span class="pre">[1,8]</span></code>。若要分析极限帧率，请将线程数改大。</p>
</dd>
<dt>profile_path：</dt><dd><p>默认关闭，统计工具日志产生路径。该参数引入的分析结果会存放在指定目录下的profiler.log文件中。</p>
</dd>
</dl>
</dd></dl>

<p>命令执行完成后，您将在控制台得到如下结果。
最终的评估结果就是 <code class="docutils literal notranslate"><span class="pre">Average</span> <span class="pre">latency</span></code> 和 <code class="docutils literal notranslate"><span class="pre">Frame</span> <span class="pre">rate</span></code>，分别表示平均单帧推理延时和模型极限帧率。
如果想获得模型在板子上运行的极限帧率，需将 <code class="docutils literal notranslate"><span class="pre">thread_num</span></code> 设置得足够大。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Running condition:
  Thread number is: <span class="m">1</span>
  Frame count   is: <span class="m">200</span>
  core number   is: <span class="m">1</span>
  Program run time: <span class="m">726</span>.604000  ms
Perf result:
  Frame totally latency is: <span class="m">714</span>.537781  ms
  Average    latency    is: <span class="m">3</span>.572689  ms
  Frame      rate       is: <span class="m">275</span>.253095  FPS
</pre></div>
</div>
<p>控制台得到的信息只有整体情况，通过 <code class="docutils literal notranslate"><span class="pre">profile_path</span></code> 控制产生的node_profiler.log文件记录了更加丰富的信息如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">{</span>
  <span class="s2">&quot;model_latency&quot;</span>: <span class="o">{</span>
    <span class="s2">&quot;MOBILENET_subgraph_0&quot;</span>: <span class="o">{</span>
      <span class="s2">&quot;avg_time&quot;</span>: <span class="m">2</span>.889,
      <span class="s2">&quot;max_time&quot;</span>: <span class="m">2</span>.889,
      <span class="s2">&quot;min_time&quot;</span>: <span class="m">2</span>.889
    <span class="o">}</span>,
    <span class="s2">&quot;MOBILENET_subgraph_0_output_layout_convert&quot;</span>: <span class="o">{</span>
      <span class="s2">&quot;avg_time&quot;</span>: <span class="m">0</span>.017265,
      <span class="s2">&quot;max_time&quot;</span>: <span class="m">0</span>.038,
      <span class="s2">&quot;min_time&quot;</span>: <span class="m">0</span>.015
    <span class="o">}</span>,
    <span class="s2">&quot;fc7_1_HzDequantize&quot;</span>: <span class="o">{</span>
      <span class="s2">&quot;avg_time&quot;</span>: <span class="m">0</span>.07467,
      <span class="s2">&quot;max_time&quot;</span>: <span class="m">0</span>.146,
      <span class="s2">&quot;min_time&quot;</span>: <span class="m">0</span>.069
    <span class="o">}</span>,
    <span class="s2">&quot;prob&quot;</span>: <span class="o">{</span>
      <span class="s2">&quot;avg_time&quot;</span>: <span class="m">0</span>.08839,
      <span class="s2">&quot;max_time&quot;</span>: <span class="m">0</span>.172,
      <span class="s2">&quot;min_time&quot;</span>: <span class="m">0</span>.052
    <span class="o">}</span>
  <span class="o">}</span>,
  <span class="s2">&quot;task_latency&quot;</span>: <span class="o">{</span>
    <span class="s2">&quot;TaskRunningTime&quot;</span>: <span class="o">{</span>
      <span class="s2">&quot;avg_time&quot;</span>: <span class="m">3</span>.43695,
      <span class="s2">&quot;max_time&quot;</span>: <span class="m">5</span>.883,
      <span class="s2">&quot;min_time&quot;</span>: <span class="m">3</span>.354
    <span class="o">}</span>,
    <span class="s2">&quot;TaskScheduleTime&quot;</span>: <span class="o">{</span>
      <span class="s2">&quot;avg_time&quot;</span>: <span class="m">0</span>.07456,
      <span class="s2">&quot;max_time&quot;</